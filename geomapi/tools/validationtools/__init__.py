"""
validationtools - a Python library for validating objects.
"""
import csv
import os
import os.path
import re
from typing import List, Tuple
from pathlib import Path
import pandas as pd
from rdflib import RDF, Graph, Literal, URIRef
import rdflib
from sklearn.neighbors import NearestNeighbors 
from scipy.spatial.transform import Rotation
import xlsxwriter
import xml.etree.ElementTree as ET
from datetime import datetime


import geomapi.utils as ut
import geomapi.utils.geometryutils as gmu
import matplotlib.pyplot as plt
import numpy as np
import open3d as o3d
# import xlsxwriter
from colour import Color
from geomapi.nodes import *
import ezdxf
from PIL import Image
import cv2

loa=rdflib.Namespace('https://docplayer.net/131921614-Usibd-level-of-accuracy-loa-specification-guide.html#')
ifc=rdflib.Namespace('http://ifcowl.openbimstandards.org/IFC2X3_Final#')

def decode_depthmap(source, resize = True, size = (8192,4096), show = False)->np.array:
    """Function to decode the depthmaps generated by the navvis processing.
 
    Args:
        source: Location of the PNG files containing the depthmap
        resize(bool): If the resulting dethmap needs to be resized to match the size of the corresponding pano, by default True
        size: size of the corresponding pano, by default 8192x4096
        show (bool, optional): Show the pano. Defaults to False.

    Returns:
        np.array(MxNx3): decoded pano
    """
    depthmap = np.asarray(Image.open(source)).astype(float)
    converted_depthmap = np.empty([np.shape(depthmap)[0], np.shape(depthmap)[1]])
    r = 0
    while r < np.shape(depthmap)[0]:
        c = 0
        while c < np.shape(depthmap)[1]:
            value = depthmap[r,c]
            depth_value = value[0] / 256 * 256 + value[1] / 256 * 256 * 256 + value[2] / 256 * 256 * 256 * 256 + value[3] / 256 * 256 * 256 * 256 * 256
            converted_depthmap[r,c] = depth_value
            c = c + 1
        r = r + 1
    if resize:
        resized_depthmap = cv2.resize(converted_depthmap,size)
        if show:
            plt.imshow(resized_depthmap, cmap="plasma")
            plt.show()
        return resized_depthmap
    else:
        if show:
            plt.imshow(converted_depthmap, cmap="plasma")
            plt.show()
        return converted_depthmap

def plot_pano_positions(panos, colors=None, headings=False, z = False):
    """
    ppcs: list of PanoPoseCollection
    headings: boolean (default: False) - plots headings as vectors
    with size 1.
    """
    
    if z:
        fig = plt.figure()
        ax = fig.add_subplot(projection='3d')
    else:
        _, ax = plt.subplots()

    n = len(panos)
    pos_xs, pos_ys = np.zeros(n), np.zeros(n)
    ori_xs, ori_ys = np.zeros(n), np.zeros(n)
    if z: 
        pos_zs = np.zeros(n)
        ori_zs = np.zeros(n)

    for i, ppc in enumerate(panos):
        kwargs = {}
        pos_xs[i] = ppc.pos_x
        pos_ys[i] = ppc.pos_y
        if z:
            pos_zs[i] = ppc.pos_z
        if colors is not None:
            kwargs['c'] = colors[i]
  
        if headings is True:
            pc_headings = get_heading(ppc.orientation)
            
            ori_xs[i] = np.cos(np.radians(pc_headings))
            ori_ys[i] = np.sin(np.radians(pc_headings))

            if z:
                pc_zenits = get_zenit(ppc.orientation)
                ori_zs[i] = np.sin(np.radians(pc_zenits))

    if z:
        ax.scatter(pos_xs, pos_ys, pos_zs)
        ax.quiver(pos_xs, pos_ys,pos_zs, ori_xs, ori_ys, ori_zs, length=0.5, color='k')
        ax.axis('auto')
        plt.title('XYZ')
    else:
        ax.scatter(pos_xs, pos_ys)
        ax.quiver(pos_xs, pos_ys, ori_xs, ori_ys, color='k')
        ax.axis('equal')
        plt.title('XY')
    plt.ion()
    plt.show()

    return plt

def get_heading(orientation):
    """
        Heading measured as angle from x to y axis. In equirectangular format
        this is the center of the pano. Headings are always positive to
        simplify subsequent calculations.

        See 'https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.transform.Rotation.html'
    """
    heading = Rotation.from_quat(orientation).as_euler('xyz', degrees=True)[-1]
    if heading < 0:
        heading = 360 + heading
    
    return heading


def get_zenit(orientation):
    """
    Angle with the vertical
    """
    zenit = Rotation.from_quat(orientation).as_euler('xyz', degrees=True)[1]
    
    return zenit

def navvis_csv_to_nodes(csvPath :str,
                        panoPath : str = None, 
                        includeDepth : bool = True, 
                        depthPath : str = None, 
                        skip:int=None, 
                        filterByFolder = True, 
                        **kwargs) -> List[panonode.PanoNode]:
    """Parse Navvis csv file and output a set of PanoNodes

    Args:
        csvPath (str): csv file path e.g. "D:/Data/pano/pano-poses.csv"
        panoPath (str, optional): _description_. Defaults to None.
        includeDepth (bool, optional): _description_. Defaults to True.
        depthPath (str, optional): _description_. Defaults to None.
        skip (int, optional): select every nth image from the xml. Defaults to None.
        filterByFolder (bool, optional): _description_. Defaults to True.

    Returns:
        List[panonode.PanoNode]: a list of Panonodes
    """
    
    assert skip == None or skip >0, f'skip == None or skip '    
    
    #open csv
    pano_csv_file = open(csvPath, mode = 'r')
    pano_csv_data = list(csv.reader(pano_csv_file))

    #Create Nodes per record
    nodes=[]
    for sublist in pano_csv_data[1::skip]:
        panoData=sublist.split('; ')
        
        fileName=panoData[1]
 
        r = Rotation.from_quat((float(sublist[7]),float(sublist[8]), float(sublist[9]), float(sublist[6]))).as_matrix()
        cartesianTransform = np.pad(r, ((0, 1), (0, 1)), mode='constant', constant_values=0)
        cartesianTransform[0,3] = float(sublist[3])
        cartesianTransform[1,3] = float(sublist[4])
        cartesianTransform[2,3] = float(sublist[5])
        cartesianTransform[3,3] = float(1)

        panoPath = Path(csvPath).parent if not panoPath else None
        depthFilename  = fileName.replace(".jpg","_depth.png")
        
        nodes.append(PanoNode(name= fileName.split(".")[0],
                              cartesianTransform=cartesianTransform,
                              timeStamp=panoData[2],
                              path=os.path.join(csvPath, fileName),
                              depthPath = os.path.join(depthPath,depthFilename),
                              use = True,
                              **kwargs))
    return nodes

def get_boundingbox_of_list_of_geometries(geometries:List[o3d.geometry.PointCloud]) -> np.array:
    """Determines the global boundingbox of a group of Node containing geometries.

    Args:
        geometries (List[Nodes]):  list of Nodes containing a resource of which the boundingbox must be determined"
            
    Returns:
        np.array[3x1]
    """
    pcd = o3d.geometry.PointCloud()
    for n in geometries:
        n.get_resource()
        if n.resource is not None:
            pcd.__iadd__(o3d.geometry.PointCloud(gmu.get_oriented_bounds(gmu.get_cartesian_bounds(n.resource))))
    cartesianBounds = gmu.get_cartesian_bounds(pcd.get_oriented_bounding_box())
    return cartesianBounds

def match_BIM_points(sources: List[o3d.geometry.PointCloud], references: List[o3d.geometry.PointCloud], referenceIds = None, resolution : float = 0.02, t00: float=0.15, wd: float = 0.62, wn: float = 0.38, threshold: float = 0.7) -> np.array:
    """Determines the accuracy of a BIM model or object using a pointcloud\n

    Args:
        1. sources(list(o3d.geometry.PointCloud)): The captured point clouds of the site.\n
        2. references(list(o3d.geometry.PointCloud)): A pointcloud per reference object\n
        3. referenceIds(list(str), optional): ID to be assigned to the points of the source point cloud\n
        4. resolution (float, optional): voxel size for the a voxel downsampling before the analysis default 0.02m\n
        5. t00(float): Threshold to which matching point will be searched default 0.15m\n
        6. wd (float): weight of the distances in the decision function default 0.62\n
        7. wn (float): weight of the normals in the decision function default 0.38\n
        8. threshold (float): minimum value to be seen as a match, default 0.7\n

    Returns:
        o3d.geometry.PointCloud: pointcloud used in the analysis linked to the identity and the distances of the points.\n
        identityArray: array containing the matching label to the BIM for each point from the point cloud.\n
        distances: array containing all the distances to the matching BIM for each point from the point cloud.\n
    """    
    #if no list, list
    sources=ut.item_to_list(sources)
    sourcePCDs=[]
    references=ut.item_to_list(references)
    referencePCDs=[]
    referenceIdentityArray=None
    
    #itterate over the reference clouds and create a Identity array
    for i,reference in enumerate(references):
        if 'PointCloud' in str(type(reference)) :
            referencePCD=reference.voxel_down_sample(resolution)
            if referenceIds:
                referenceIdentityArray=np.vstack((referenceIdentityArray,np.full((len(referencePCD.points), 1), referenceIds[i])))
            else:
                referenceIdentityArray=np.vstack((referenceIdentityArray,np.full((len(referencePCD.points), 1), i+1)))
        referencePCDs.append(referencePCD)
    #Join the reference clouds together to one reference cloud
    referencePCD=gmu.join_geometries(referencePCDs)
    
    #check if the reference cloud has normals, if not compute them, this will be less accurate than when using the normals of the meshes
    if not referencePCD.has_normals():
        referencePCD.estimate_normals()
    referencePCD.normalize_normals()

    #Flatten the identity array and remove the first (None) value
    referenceIdentityArray=referenceIdentityArray.flatten()
    referenceIdentityArray=np.delete(referenceIdentityArray,0)

    #Check if the boundingboxes of the source clouds lie within the boundingbox of the reference
    #when the reference covers more then the captured data
    inliers = gmu.get_box_inliers(referencePCD.get_oriented_bounding_box(), [geometry.get_oriented_bounding_box() for geometry in sources], t_d = 500) 
    #when the reference covers less than the captured data
    inliers += gmu.get_box_intersections(referencePCD.get_oriented_bounding_box(), [geometry.get_oriented_bounding_box() for geometry in sources])
    
    if not inliers:
        #If reference and source share no overlap the sources containing no overlap will be ignored
        return None
    
    for i,source in enumerate(sources): 
        if i in inliers:      
            if 'PointCloud' in str(type(source)) :
                sourcePCD=source.voxel_down_sample(resolution)
            sourcePCDs.append(sourcePCD)
    

    #Join them in one source cloud for computations can be limiting for very large clouds
    joinedPCD=gmu.join_geometries(sourcePCDs)
    
    identityArray= [0] * len(joinedPCD.points)
    distances = [0.0] * len(joinedPCD.points)


    #Create a KDtree of the reference
    referenceTree = o3d.geometry.KDTreeFlann(referencePCD)
    
    #compute the c2c distances between both clouds, without matching. This speeds up the computations significantly
    c2cdistances = joinedPCD.compute_point_cloud_distance(referencePCD)
    #Itterate over every captured point within the tresholddistance
    for i, point in enumerate(joinedPCD.points):
        
        if c2cdistances[i] < t00:
            #Search for the k=20 nearest neighbours with a maximum distance of t00
            [k,inliers ,ignore] = referenceTree.search_hybrid_vector_3d(point, t00, 20)
            #When neighbours are found within a distance t00 ierate over them
            if k > 0:
                localdistances = [0.0]*len(np.asarray(inliers))
                distanceparameters = [0.0]*len(np.asarray(inliers))
                normalparameters = [0.0]*len(np.asarray(inliers))
                similarities = [0.0]*len(np.asarray(inliers))

                #For every found neighbour compute the distance and the normal parameters
                for id, inlier in enumerate(inliers):
                    #Compute the actual 3d distance (is not equal to the distance returned by o3d.search_hybrid_vector!)
                    localdistances[id] = np.sqrt(np.sum((point-referencePCD.points[inlier])**2, axis=0))
                    #compute the distance parameter
                    distanceparameters[id] = (t00 - localdistances[id])/t00
                    #compute the normal parameter
                    normalparameters[id] = np.abs(np.dot(np.asarray(joinedPCD.normals[i]), np.asarray(referencePCD.normals[inlier])))
                    #compute the similarity between point p and the specifik neighbour k
                    similarities[id] = wn * np.power(normalparameters[id],3) + distanceparameters[id] * wd

                #Search for the maximal similarity which should be above the defined threshold and assign the correct label and distance to the according arrays
                if similarities[np.argmax(similarities)] > 0.7:
                    identityArray[i] = referenceIdentityArray[inliers[np.argmax(similarities)]]
                    distances[i] = localdistances[np.argmax(similarities)]
    #Filter out points not matched to any element
    resultPCD = joinedPCD.select_by_index(np.where(np.asarray(identityArray) != '0')[0])
    
    i = 0
    identityArray2 = []
    distances2 = []
    while i < len(identityArray):
        if not identityArray[i] == 0:
            identityArray2.append(identityArray[i])
            distances2.append(distances[i])
        i += 1

    return resultPCD, identityArray2, distances2

def compute_LOA(identities, distances, t00: float = 0.15, t10: float = 0.10, t20: float = 0.05, t30: float = 0.015, byElement: bool = False, limit: float = 0.95):
    """Function which uses distances and a linked identity array to determine the LOA percentages 

    Args:
        identities (nx1-array): Array containing the identity of the distance between two matched points
        distances (nx1 array): Array containing the distances between two matched points
        t00 (float, optional): Maximum distance to be used in the analysis. Defaults to 0.15.
        t10 (float, optional): Upper bound of the LOA10 bracket. Defaults to 0.10.
        t20 (float, optional): Upper bound of the LOA20 bracket. Defaults to 0.05.
        t30 (float, optional): Upper bound of the LOA10 bracket. Defaults to 0.015.
        byElement (bool, optional): If the LOA must be computed per element of for the enitre cloud. Defaults to False.
        limit (float, optional): Percentage of inliers between two brackets needed to assign the LOA label. Defaults to 0.95.

    Returns:
        LOA: List of LOAs per element (id, [LOA10, LOA20, LOA30], label)
    """
    LOA = []
    if byElement: 
        for identity in np.unique(identities):
            if not identity  == 0:
                places = np.where(np.asarray(identities) == identity)[0]

                LOA00Inliers = 0
                LOA10Inliers = 0
                LOA20Inliers = 0
                LOA30Inliers = 0

                for place in places :
                    if distances[place] <= t00:
                        LOA00Inliers += 1
                    if distances[place] <= t10:
                        LOA10Inliers += 1
                    if distances[place] <=t20:
                        LOA20Inliers += 1
                    if distances[place] <= t30:
                        LOA30Inliers += 1

                if LOA00Inliers > 0:
                    LOA10 = LOA10Inliers/LOA00Inliers
                    LOA20 = LOA20Inliers/LOA00Inliers
                    LOA30 = LOA30Inliers/LOA00Inliers

                    if LOA30 > limit:
                        label = 'LOA30'
                    elif LOA20 > limit:
                        label = 'LOA20'
                    elif LOA10 > limit:
                        label = 'LOA10'
                    else: 
                        label = None
                    LOA.append((identity,[LOA10, LOA20, LOA30], label))
    else:
        LOA00Inliers = 0
        LOA10Inliers = 0
        LOA20Inliers = 0
        LOA30Inliers = 0

        for d in distances :
            if d <= t00:
                LOA00Inliers += 1
            if d <= t10:
                LOA10Inliers += 1
            if d <=t20:
                LOA20Inliers += 1
            if d <= t30:
                LOA30Inliers += 1

        if LOA00Inliers > 0:
            LOA10 = LOA10Inliers/LOA00Inliers
            LOA20 = LOA20Inliers/LOA00Inliers
            LOA30 = LOA30Inliers/LOA00Inliers
            if LOA30 > limit:
                label = 'LOA30'
            elif LOA20 > limit:
                label = 'LOA20'
            elif LOA10 > limit:
                label = 'LOA10'
            else:
                label = None
                    
            LOA.append((None,[LOA10, LOA20, LOA30], label))
    return LOA

def plot_histogram(identities, distances, buckets: int = None, interval: float = None, dmax:float = 0.1, byElement = False, bins = None, directory = None, show = True):
    """Function to plot distances between the captured cloud and the reference cloud

    Args:
        identities (nx1-array): Array containing the identity of the distance between two matched points
        distances (nx1 array): Array containing the distances between two matched points
        buckets (int, optional): Number of intervals the data will be seperated. Defaults to None.
        interval (float, optional): distance between the upper and lower bound of an interval. Defaults to None.
        dmax (float, optional): Distances higher then this distance will be ignored. Defaults to 0.1.
        byElement (bool, optional): If the LOA must be computed per element of for the enitre cloud. Defaults to False.
        bins (1xn array): Can be used to describe custom bin boundries (intervals must be equal). Defaults to None.
        directory (path, optional): When provided the histograms will be saved in the form of a PNG to this directory. Defaults to None.
        show (bool, optional): When set on true the histograms will be visualized. Defaults to True.
    """
    directory=Path(directory)
    
    #create directory if needed
    os.mkdir(directory) if directory and not directory.exists() else None


    if buckets:
        max = np.max(np.asarray(distances))
        if max > dmax:
            max = dmax
        
        min = np.min(np.asarray(distances))
        if min < 0:
            min = 0  
        range = max - min 
        interval = range / buckets
        lb = 0
        ub = lb+interval

        bins = [lb]
        while ub <= dmax:
            bins.append(ub)
            ub +=interval
    if interval:
        lb = 0
        ub = lb+interval

        bins = [lb]
        while ub <= dmax:
            bins.append(ub)
            ub +=interval 
    if not bins:
        max = np.max(np.asarray(distances))
        if max > dmax:
            max = dmax
        interval = 0.005
        lb = 0
        ub = lb+interval
        bins = [lb]
        while ub <= dmax:
            bins.append(ub)
            ub +=interval

    if byElement:
        for identity in np.unique(identities):
            elementDistances = []
            if not identity  == "0":
                places = np.where(np.asarray(identities) == identity)[0]
                for place in places :
                    elementDistances.append(distances[place])
                plt.hist(elementDistances, bins = bins)
                plt.title(identity.split("file:///")[1])
                if directory:
                    if not directory.endswith("histograms"):
                        directory = os.path.join(directory, "histograms")
                        if not os.path.exists(directory):
                            os.mkdir(directory)
                    filename = os.path.join(directory, identity.split("file:///")[1] + ".PNG")
                    plt.title(identity.split("file:///")[1])
                    plt.savefig(filename)
                    plt.clf()
                if show:
                    plt.show()

    else:
        places = np.where(np.asarray(identities) != '0')[0]
        elementDistances = [distances[place] for place in places]
        plt.hist(elementDistances, bins = bins)
        if directory:
            filename = os.path.join(directory, 'histogram' + ".PNG")
            plt.savefig(filename)
        if show:
            plt.show()

def color_point_cloud_by_LOA(pointcloud: o3d.geometry.PointCloud, identities, distances, t00: float = 0.15, t10: float = 0.10, t20: float = 0.05, t30: float = 0.015, byElement: bool = False): 
    """Colors each point by its computed LOA based on the distance between the matched points of the reference and the source cloud

    Args:
        pointcloud (o3d.geometry.PointCloud): Point cloud from the LOA determination or pointcloud matching its the returned indeces
        identities (nx1-array): Array containing the identity of the distance between two matched points
        distances (nx1 array): Array containing the distances between two matched points
        t00 (float, optional): Maximum distance to be used in the analysis. Defaults to 0.15.
        t10 (float, optional): Upper bound of the LOA10 bracket. Defaults to 0.10.
        t20 (float, optional): Upper bound of the LOA20 bracket. Defaults to 0.05.
        t30 (float, optional): Upper bound of the LOA10 bracket. Defaults to 0.015.
        byElement (bool, optional): If the LOA must be computed per element of for the enitre cloud. Defaults to False.
        
    Returns:
        o3d.geometry.PointCloud()
    """
    pointcloud.paint_uniform_color([0.5,0.5,0.5])
    if byElement:
        elementClouds = []
        for identity in np.unique(identities):
            elementDistances = []
            if not identity  == 0:
                places = np.where(np.asarray(identities) == identity)[0]
                elementCloud = pointcloud.select_by_index(places)
                for place in places :
                    elementDistances.append(distances[place])
                for i, d in enumerate(elementDistances):
                    if d <= t00:
                        np.asarray(elementCloud.colors)[i] = [1,0,0]
                    if d <= t10:
                        np.asarray(elementCloud.colors)[i] = [1,0.76,0]
                    if d <=t20:
                        np.asarray(elementCloud.colors)[i] = [1,1,0]
                    if d <= t30:
                        np.asarray(elementCloud.colors)[i] = [0,1,0]
                elementClouds.append(elementCloud)
        return elementClouds
    else:
        for i, d in enumerate(distances):
            if not identities[i] == 0:
                if d <= t00:
                    np.asarray(pointcloud.colors)[i] = [1,0,0]
                if d <= t10:
                    np.asarray(pointcloud.colors)[i] = [1,0.76,0]
                if d <=t20:
                    np.asarray(pointcloud.colors)[i] = [1,1,0]
                if d <= t30:
                    np.asarray(pointcloud.colors)[i] = [0,1,0]
        return pointcloud

def color_point_cloud_by_distance(pointcloud: o3d.geometry.PointCloud, identities:np.array, distances:np.array, buckets: int = 5, dmax:float = 0.1, byElement: bool = False)->o3d.geometry.PointCloud:
    """Colorizes the resulting point cloud of the LOA analysis in a gradient by distance between the matched points from the reference and the source (very slow).\n

    **NOTE**: use sklearn to make this faster.

    Args:
        1. pointcloud (o3d.geometry.PointCloud): Point cloud from the LOA determination or pointcloud matching its the returned indeces.\n
        2. identities (nx1-array): Array containing the identity of the distance between two matched points.\n
        3. distances (nx1 array): Array containing the distances between two matched points.\n
        4. buckets (int, optional): Number of intervals to be colored in. Defaults to 5.\n
        5. dmax (float, optional): Distances higher then this distance will be ignored. Defaults to 0.1m.\n
        6. byElement (bool, optional): If the LOA must be computed per element of for the enitre cloud. Defaults to False.\n

    Returns:
        o3d.geometry.PointCloud
    """
    max = np.max(np.asarray(distances))
    if max > dmax:
        max = dmax
    
    min = np.min(np.asarray(distances))
    range = max - min 
    interval = range / buckets
    lb = 0
    ub = lb+interval

    pointcloud.paint_uniform_color([0.5,0.5,0.5])

    green = Color("green")
    colors = list(green.range_to(Color("red"),buckets))
    colors = [c.rgb for c in colors]
    
    
    if byElement:
        elementClouds = []
        for identity in np.unique(identities):
            lb = 0
            ub = lb+interval
            elementDistances = []
            if not identity  == 0:
                bucket = 0
                places = np.where(np.asarray(identities) == identity)[0]
                elementCloud = pointcloud.select_by_index(places)
                for place in places :
                    elementDistances.append(distances[place])

                while ub <= max:
                    places2 = np.where(np.asarray(elementDistances) <= ub)[0]
                    places3 = np.where(np.asarray(elementDistances) > lb)[0]
                    for place2 in places2:
                        if place2 in places3:
                            np.asarray(elementCloud.colors)[place2] = colors[bucket]
                    lb = ub
                    ub += interval
                    bucket +=1
                elementClouds.append(elementCloud)
        return elementClouds
    else:
        bucket = 0
        while ub <= max:
            places2 = np.where(np.asarray(distances) <= ub)[0]
            places3 = np.where(np.asarray(distances) > lb)[0]
            for place2 in places2:
                if place2 in places3:
                    np.asarray(pointcloud.colors)[place2] = colors[bucket]
            lb = ub
            ub += interval
            bucket +=1
        return pointcloud

def csv_by_LOA(directory:str, LOAs, visibility=None):
    """Function to report the LOA analysis in a csv file.\n

    Args:
        1. directory (path): directory where the report must be saved.\n
        2. LOAs (_type_): results of the LOA computation.\n
        3. visibility (_type_, optional): array containing the per element visibility.\n

    Returns:
        returns true when succeded.
    """
    if not os.path.exists(directory):
        os.mkdir(directory)
    csvFilename = "LOA_Report1.csv"
    csvPath = os.path.join(directory, csvFilename)
    if visibility:
        header = ['Name','LOA', 'LOA10', 'LOA20', 'LOA30', 'Theoretical visibility']
    else:
        header = ['Name','LOA', 'LOA10', 'LOA20', 'LOA30']
    csvFile = open(csvPath, 'w')
    csvWriter = csv.writer(csvFile)
    csvWriter.writerow(header)

    for LOA in LOAs:
        if not LOA[0]  == '0':
            if visibility:
                vis = [v[1] for v in visibility if str(v[0]) == LOA[0]]
                data = [LOA[0], LOA[2], LOA[1][0], LOA[1][1], LOA[1][2], vis[0]]
            else: 
                data = [LOA[0], LOA[2], LOA[1][0], LOA[1][1], LOA[1][2]]
            csvWriter.writerow(data)
    csvFile.close()
    return True

def excel_by_LOA(directory, LOAs, visibility= None):
    """Function to report the LOA analysis in an excel file

    Args:
        directory (path): directory where the report must be saved
        LOAs (_type_): results of the LOA computation
        visibility (_type_, optional): array containing the per element visibility

    Returns:
        returns true when succeded
    """
    if not os.path.exists(directory):
        os.mkdir(directory)
    xlsxFilename = "LOA_Report.xlsx"
    xlsxPath = os.path.join(directory, xlsxFilename)
    workbook = xlsxwriter.Workbook(xlsxPath)
    worksheet = workbook.add_worksheet()
    worksheet.write(0,0,'Name')
    worksheet.write(0,1,'LOA')
    worksheet.write(0,2, 'LOA10')
    worksheet.write(0,3, 'LOA20')
    worksheet.write(0,4, 'LOA30')
    if visibility:
        worksheet.write(0,5, 'Theoretical visibility')
    xlsxRow = 1

    for LOA in LOAs:
        if not LOA[0]  == '0':
            worksheet.write(xlsxRow, 0, LOA[0])
            worksheet.write(xlsxRow, 1, LOA[2])
            worksheet.write(xlsxRow, 2, LOA[1][0])
            worksheet.write(xlsxRow, 3, LOA[1][1])
            worksheet.write(xlsxRow, 4, LOA[1][2])
            if visibility:
                vis = [v[1] for v in visibility if str(v[0]) == LOA[0]]
                worksheet.write(xlsxRow, 5, vis[0])
        xlsxRow += 1 
    workbook.close()

    return True

def color_BIMNode(LOAs, BIMNodes: List[BIMNode]):
    """Colors the BIM mesh geometries in the computed LOA color

    Args:
        LOAs (_type_): results of the LOA analysis
        BIMNodes (List[BIMNode]): List of the BIMNodes in the project
    """
    for BIMNode in BIMNodes:
        if BIMNode.resource:
                BIMNode.resource.paint_uniform_color([0.5,0.5,0.5])
    for BIMNode in BIMNodes:
        for LOA in LOAs:
            if LOA[0] == BIMNode.subject:
                if not BIMNode.resource:
                    BIMNode.get_resource()
                if LOA[2] == 'LOA10':
                    BIMNode.resource.paint_uniform_color([1,0.76,0])
                if LOA[2] == 'LOA20':
                    BIMNode.resource.paint_uniform_color([1,1,0])
                if LOA[2] == 'LOA30':
                    BIMNode.resource.paint_uniform_color([0,1,0])


def cad_show_lines(dxf_path:str):

    doc = ezdxf.readfile(dxf_path)

    # Extract all line entities from the DXF file
    msp = doc.modelspace()
    lines = msp.query("LINE")

    # Plot all the lines using Matplotlib
    for line in lines:
        x1, y1, _ = line.dxf.start
        x2, y2, _ = line.dxf.end
        plt.plot([x1, x2], [y1, y2])

    plt.show()

# def create_lineset(line, points:np.ndarray):
#     pcd = o3d.geometry.PointCloud()
#     pcd.points = o3d.utility.Vector3dVector(np.array(points))
#     colors = [line[2]] * len(points) #! this is sketchy
#     pcd.colors = o3d.utility.Vector3dVector(np.array(colors) / 255.0)
    
#     lineset = o3d.geometry.LineSet.create_from_point_cloud_correspondences(pcd, pcd, [(i, i+1) for i in range(len(points)-1)])
#     lineset.paint_uniform_color(np.array(line[2]) / 255.0)
#     lineset.line_width = line[4]
    
#     return lineset

def sample_pcd_from_linesets(linesets:List[o3d.geometry.LineSet],step_size:float=0.1)-> Tuple[o3d.geometry.PointCloud,np.ndarray]:
    """Sample a point cloud from a set of o3d.geometry.LineSet elements (color is inherited)

    Args:
        linesets (List[o3d.geometry.LineSet]): linesets to sample. 
        step_size(float,optional):spacing between points. Defaults to 0.1m.

    Returns:
        Tuple[List[o3d.geometry.PointCloud],np.ndarray]: point_clouds, identityarray with integers of the origin of the points
    """
    point_clouds=o3d.geometry.PointCloud()
    ilist=[]
    jlist=[]
    
    for i,lineset in enumerate(linesets):

        # Get line segments from the LineSet
        pointArray=np.asarray(lineset.points)
        points = []

        for j,line in enumerate(np.asarray(lineset.lines)):
            #get start and end
            start_point = pointArray[line[0]]
            end_point = pointArray[line[1]]
            #get direction and length
            direction = end_point - start_point
            length = np.linalg.norm(direction)
            #compute number of points
            num_points = int(length / step_size)
            if num_points > 0:
                step = direction / num_points
                p=[start_point + r * step for r in range(num_points + 1)]
                points.extend(p)
                
                #keep track of identity of the points
                ilist.extend(np.full((len(p), 1), i))
                jlist.extend(np.full((len(p), 1), j))
                
        # Convert the sampled points to an o3d PointCloud
        point_cloud = o3d.geometry.PointCloud()
        point_cloud.points = o3d.utility.Vector3dVector(points)
        color=lineset.colors[0]
        point_cloud.paint_uniform_color(color)
        point_clouds+=point_cloud
        
    #compile identidyarray & point cloud
    indentityArray=np.column_stack((np.array(ilist),np.array(jlist)))

    return point_clouds,indentityArray

# def select_lineset_inliers(linesets,points)->o3d.geometry.LineSet:
#     linesetselection=np.empty((points.shape[0],2))

#     #iterate through linesets
#     for i,p in enumerate(points):
        
#         for linesetidx,lineset in enumerate(sublinesets):
            
#             #iterate through line
#             for lineidx,line in enumerate(lineset.lines):
#                 # # get p0 and p1 in the size of the input points
#                 # p0=np.tile(lineset.points[line[0]], (points.shape[0], 1)) 
#                 # p1=np.tile(lineset.points[line[1]], (points.shape[0], 1))
#                 p0=lineset.points[line[0]]
#                 p1=lineset.points[line[1]]
                
#                 #test if any point is on the line  -> # 0.0 <= dot(p1-p0,p-p0)/|p-p0| <= 1.0
#                 # print(np.sum((p-p0)**2))
#                 dot=np.dot(p1-p0,p-p0)/np.sum((p-p0)**2)
                
#                 if (dot>=0) & (dot <=1 ):
#                     linesetselection[i,0]=linesetidx
#                     linesetselection[i,1]=lineidx
#     return(linesetselection)               
#             # print('line')
#             # dot=np.sum(np.dot(p1-p0,(points-p0).T),axis=1) /np.sum((points-p0)**2,axis=1)
        
# #         # create tuple 
# #         np.where((dot>=0) & (dot <=1 ),
# #                  (linesetidx,lineidx,dot),
# #                  (np.nan,np.nan,dot))
            
        
# # return linesetselection.append((linesetidx,lineidx,distance))
        
# # return True if (dot>=0 or dot <=1 ) else False


# def create_unique_mapping(array:np.ndarray)->Tuple[np.ndarray,np.ndarray]:
#     """Create a unique mapping of an array

#     Args:
#         array (np.ndarray): first column of the array will be used for the sorting.

#     Returns:
#         Tuple[np.ndarray,np.ndarray]: unique_values, mapping (shape of input array)
#     """
#     #get first array #! this is a bit flawed and supposes that every x-value is unique
#     a=array[:,0]
#     unique_values=np.unique(array,axis=0)
    
#     # build dictionary
#     fwd = np.argsort(a)
#     asorted = a[fwd]
#     keys = np.unique(asorted) 
#     lower = np.searchsorted(asorted, keys)
#     higher = np.append(lower[1:], len(asorted))

#     inv = {key: fwd[lower_i:higher_i]
#             for key, lower_i, higher_i
#             in zip(keys, lower, higher)}
    
#     # remap values to 0,1,2,....
#     mapping=np.zeros(array.shape[0])
#     i=0
#     for _,value in inv.items():
#             for v in value:
#                     mapping[v]=i
#             i+=1
    
#     return unique_values,mapping

def get_linesets_inliers_in_box(linesets:List[o3d.geometry.LineSet],box:o3d.geometry.OrientedBoundingBox,point_cloud:o3d.geometry.PointCloud,identityArray:np.ndarray) -> List[o3d.geometry.LineSet]:
    """Returns the segments of the linesets that have sampled pointcloud points falling within a certain bounding box.
    This function should be used together with:\\
        1. vt.sample_pcd_from_linesets(linesets,step_size=0.1)\\
        2.vt.create_selection_box_from_image_boundary_points(n,roi,meshNode.resource,z=5) \\

    Args:
        linesets (List[o3d.geometry.LineSet]): linesets from which the segments will be selected
        box (o3d.geometry.OrientedBoundingBox): bounding box that is used to filter the point cloud points
        point_cloud (o3d.geometry.PointCloud): sampled points on the linesets
        identityArray (np.ndarray): array with integers that reflect which point cloud point belongs to which lineset

    Returns:
        List[o3d.geometry.LineSet]: _description_
    """
    assert len(np.asarray(point_cloud.points))==identityArray.shape[0], f'length of point cloud and identityarray are not equal'
        
    #compute point_cloud inliers in box
    idxList=box.get_point_indices_within_bounding_box(point_cloud.points)
    if len(idxList)==0:
        return []    
        
    #retrieve which linesets are visible in the box
    idx=identityArray[idxList]
    unique_rows, _ = np.unique(idx, axis=0, return_inverse=True)
    
    #split lists per lineset -> create split_rows dictionary of mapping
    split_rows = {}
    for row in unique_rows:
        key = row[0]
        if key not in split_rows:
            split_rows[key] = []
        split_rows[key].append(row)
    
    #get linesegments and build new linesets
    sublinesets=[]
    for key,value in split_rows.items():
        #get lineset
        lineset=linesets[key]
        #get linesegments
        linesegments=[linesets[key].lines[v[1]] for v in value]
        #create new linesets -> currently still has all redundant points
        line_set = o3d.geometry.LineSet() 
        line_set.points = o3d.utility.Vector3dVector(lineset.points)  
        line_set.lines = o3d.utility.Vector2iVector(linesegments)
        sublinesets.append(line_set)
    return sublinesets

def create_selection_box_from_image_boundary_points(n:ImageNode,roi:Tuple[int,int,int,int],mesh:o3d.geometry.TriangleMesh,z:float=5)->o3d.geometry.OrientedBoundingBox:
    """Create a selection box from an ImageNode, a region of interest (roi) and a mesh to raycast.
    A o3d.geometry.OrientedBoundingBox will be created on the location of the intersection of the rays with the mesh.
    The height of the box is determined by the offset of z in both positive and negative Z-direction

    Args:
        n (ImageNode): Imagenode used for the raycasting (internal and external camera paramters)
        roi (Tuple[int,int,int,int]): region of interest (rowMin,rowMax,columnMin,columnMax)
        mesh (o3d.geometry.TriangleMesh): mesh used for the raycasting
        z (float, optional): offset in height of the bounding box. Defaults to [-5m:5m].

    Returns:
        o3d.geometry.OrientedBoundingBox or None (if not all rays hit the mesh)
    """
    box=None
    
    #create rays for boundaries
    uvCoordinates=np.array([[roi[0],roi[2]], # top left
                            [roi[0],roi[3]], # top right
                            [roi[1],roi[2]], # bottom left
                            [roi[1],roi[3]] # bottom right
                            ])
    # transform uvcoordinates  to world coordinates to rays   
    rays=n.create_rays(uvCoordinates)
    
    # cast rays to 3D mesh 
    distances,_=gmu.compute_raycasting_collisions(mesh,rays)
    
    if all(np.isnan(distances)==False): #if all rays hit
        #compute endpoints 
        _,endpoints=gmu.rays_to_points(rays,distances)
        
        #create box of projected points
        points=np.vstack((gmu.transform_points(endpoints,transform=np.array([[1,0,0,0],[0,1,0,0],[0,0,1,z],[0,0,0,1]])),
                        gmu.transform_points(endpoints,transform=np.array([[1,0,0,0],[0,1,0,0],[0,0,1,-z],[0,0,0,1]]))))
        box=o3d.geometry.OrientedBoundingBox.create_from_points(o3d.cpu.pybind.utility.Vector3dVector(points))
        box.color=[1,0,0]     
    return box 

# NOTE remove obsolete classes -> ImageNodes
class AlignmentPose():
    """
    An alignment pose is used to transform a collection of pano poses.
    """

    def __init__(self, x :float, y: float, z: float, orientation: tuple, name: str = None, validate : bool = True):
        """Creation of the alignmentpose

        Args:\n
            x (float): x-coordinate\n
            y (float): y-coordinate\n
            z (float): z-coordinate\n
            orientation (tuple): rotation quaternion\n
            name (str, optional): the name of the pose. Defaults to None.\n
            validate (bool, optional): check if the rotation is a valid quaternion. Defaults to True.\n
        """
        if validate is True:
            assert(isinstance(orientation, tuple) and len(orientation) == 4)

        self.x = x
        self.y = y
        self.z = z
        self.orientation = orientation
        self.name = name


class PanoPose(AlignmentPose):
    """
    A pano pose gives the position, orientation and optionally time and name of
    a pano.
    """

    def __init__(self, x, y, z, orientation, time=None, name=None, validate=True):
        """
        """
        if validate is True:
            if time is not None:
                assert(isinstance(time, datetime))

        super().__init__(x, y, z, orientation, name)

        self.time = time

    @property
    def heading(self):
        """
        Heading measured as angle from x to y axis. In equirectangular format
        this is the center of the pano. Headings are always positive to
        simplify subsequent calculations.

        See 'https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.transform.Rotation.html'
        """
        heading = Rotation.from_quat(
                self.orientation).as_euler('xyz', degrees=True)[-1]

        if heading < 0:
            heading = 360 + heading

        return heading

    @property
    def zenit(self):
        """
        Angle with the vertical
        """
        zenit = Rotation.from_quat(
                self.orientation).as_euler('xyz', degrees=True)[0]

        return zenit


    def get_direction_to_other_pose(self, other_pose, validate=True):
        """
        Angle from x to y with 'self' in the origin. Angles are always positive
        to simplify subsequent calculations.

        other_pose: instance of 'self'
        """
        if validate is True:
            assert(isinstance(self, self.__class__))

        x = other_pose.x - self.x
        y = other_pose.y - self.y
        angle = np.degrees(np.arctan2(y, x))

        if angle < 0:
            angle = 360 + angle

        return angle


class PanoPoseCollection():
    """
    A collection of pano poses with position, orientation and time.
    """

    def __init__(self, pos_xs, pos_ys, pos_zs, ori_xs, ori_ys, ori_zs,
        ori_ws, times=None, validate=True):
        """
        """
        if validate is True:
            assert(len(pos_xs) == len(pos_ys) == len(pos_zs) == len(ori_xs) ==
                len(ori_ys) == len(ori_zs) == len(ori_ws))
            if times is not None:
                assert(len(times) == len(ori_ws))

        self.pos_xs = pos_xs
        self.pos_ys = pos_ys
        self.pos_zs = pos_zs
        self.ori_xs = ori_xs
        self.ori_ys = ori_ys
        self.ori_zs = ori_zs
        self.ori_ws = ori_ws
        self.times = times

    def __len__(self):
        """
        """
        return len(self.ori_ws)

    def __getitem__(self, i):
        """
        """
        pano_pose = PanoPose(self.pos_xs[i], self.pos_ys[i], self.pos_zs[i],
            (self.ori_xs[i], self.ori_ys[i], self.ori_zs[i], self.ori_ws[i]),
            self.times[i], name=str(i), validate=False)

        return pano_pose

    def __iter__(self):
        """
        """
        for i in range(len(self)):
            yield self[i]

    @property
    def headings(self):
        """
        """
        return [p.heading for p in self]

    @property
    def zenits(self):
        """
        """
        return [p.zenit for p in self]

    @property
    def box(self):
        """
        Give bounding box of pano collection.
        """
        x_min, x_max = self.pos_xs.min(), self.pos_xs.max()
        y_min, y_max = self.pos_ys.min(), self.pos_ys.max()

        return x_min, x_max, y_min, y_max

    def transform(self, aligment_pose, validate=True):
        """
        """
        if validate is True:
            assert(isinstance(aligment_pose, AlignmentPose))

        r = Rotation.from_quat(aligment_pose.orientation)
        coordinates = np.matmul(
            r.as_matrix(), np.array([self.pos_xs, self.pos_ys, self.pos_zs]))
        pos_xs = coordinates[0] + aligment_pose.x
        pos_ys = coordinates[1] + aligment_pose.y
        pos_zs = coordinates[2] + aligment_pose.z

        # TODO: Optimise this part so operation is performed at once
        ori_xs, ori_ys, ori_zs, ori_ws = [], [], [], []
        for p in self:
            pr = r * Rotation.from_quat(p.orientation)
        
            ori_x, ori_y, ori_z, ori_w = pr.as_quat()
            ori_xs.append(ori_x)
            ori_ys.append(ori_y)
            ori_zs.append(ori_z)
            ori_ws.append(ori_w)

        ppc = PanoPoseCollection(
            pos_xs, pos_ys, pos_zs, ori_xs, ori_ys, ori_zs, ori_ws, self.times)

        return ppc

    def plot(self, headings=False, size=None):
        """
        headings: boolean (default: False) - plots headings as vectors
        with size 1.
        """
        plot_pose_collections_3D(
            [self], colors=['k'], headings=headings, size=size)


def read_leica_pano_poses_xml(filespec):
    """
    Read xml file from .e57 exported with Leica Cyclone.
    """
    root = ET.parse(filespec).getroot()

    ns = '{http://www.astm.org/COMMIT/E57/2010-e57-v1.0}'

    datetimes = []
    pos_xs, pos_ys, pos_zs = [], [], []
    ori_xs, ori_ys, ori_zs = [], [], []
    ori_ws = []

    for i, pano in enumerate(root.findall('.//{}vectorChild'.format(ns))):
        datetimes.append(datetime.fromtimestamp(float(
            pano.find('{}acquisitionDateTime'.format(ns)).find(
                '{}dateTimeValue'.format(ns)).text)))

        pose = pano.find('{}pose'.format(ns))
        if pose is None and i == 0: ## no translation and rotation given for first point
            ori_x, ori_y, ori_z = 0, 0, 0
            ori_w = 1
            pos_x, pos_y, pos_z = 0, 0, 0
        else:
            rotation = pose.find('{}rotation'.format(ns))
            ori_x = rotation.find('{}x'.format(ns)).text
            ori_y = rotation.find('{}y'.format(ns)).text
            ori_z = rotation.find('{}z'.format(ns)).text
            ori_w = rotation.find('{}w'.format(ns)).text
            if ori_x is None:
                ori_x = 0
            if ori_y is None:
                ori_y = 0
            if ori_z is None:
                ori_z = 0
            if ori_w is None:
                ori_w = 1
            
            ori_x = float(ori_x)
            ori_y = float(ori_y)
            ori_z = float(ori_z)

            translation = pose.find('{}translation'.format(ns))
            pos_x = float(translation.find('{}x'.format(ns)).text)
            pos_y = float(translation.find('{}y'.format(ns)).text)
            pos_z = float(translation.find('{}z'.format(ns)).text)

        ## Correct for Leica pano's (at least export from Cyclone) pointing
        ## towards positive y axis with center. This should be the positive
        ## x-axis so have to rotate 90 degrees.
        r = (Rotation.from_quat((ori_x, ori_y, ori_z, ori_w)) *
            Rotation.from_euler('z', 90, degrees=True))
        ori_x, ori_y, ori_z, ori_w = r.as_quat()

        ori_xs.append(ori_x)
        ori_ys.append(ori_y)
        ori_zs.append(ori_z)
        ori_ws.append(ori_w)
        pos_xs.append(pos_x)
        pos_ys.append(pos_y)
        pos_zs.append(pos_z)

    ppc = PanoPoseCollection(
        np.array(pos_xs), np.array(pos_ys), np.array(pos_zs),
        np.array(ori_xs), np.array(ori_ys), np.array(ori_zs),
        np.array(ori_ws),
        np.array(datetimes), validate=False)

    return ppc


def read_navvis_pano_poses_csv(filespec):
    """
    NavVis provides a pano-poses.csv file in each post-processed dataset. It
    holds the timestamp, position and orientation of each pano in the dataset.
    """
    with open(filespec) as f:
        data = f.read().split('\n')

    n = len(data) - 2

    datetimes = []
    pos_xs, pos_ys, pos_zs = np.zeros(n), np.zeros(n), np.zeros(n)
    ori_xs, ori_ys, ori_zs = np.zeros(n), np.zeros(n), np.zeros(n)
    ori_ws = np.zeros(n)
    for i, l in enumerate(data[1:-1]):
        r = l.split('; ')
        datetimes.append(datetime.fromtimestamp(float(r[2])))
        pos_xs[i] = r[3]
        pos_ys[i] = r[4]
        pos_zs[i] = r[5]
        ori_xs[i] = r[7]
        ori_ys[i] = r[8]
        ori_zs[i] = r[9]
        ori_ws[i] = r[6]

    ppc = PanoPoseCollection(pos_xs, pos_ys, pos_zs, ori_xs, ori_ys, ori_zs,
        ori_ws, np.array(datetimes), validate=False)

    return ppc


def read_navvis_alignment_xml(filespec):
    """
    Read xml file generated by NavVis aligment tool.
    """
    root = ET.parse(filespec).getroot()

    alignment_poses = []
    for dataset in root.findall('.//dataset'):
        name = dataset.find('name').text
        position = dataset.find('.//position')
        pos_x = float(position.find('x').text)
        pos_y = float(position.find('y').text)
        pos_z = float(position.find('z').text)
        orientation = dataset.find('.//orientation')
        ori_x = float(orientation.find('x').text)
        ori_y = float(orientation.find('y').text)
        ori_z = float(orientation.find('z').text)
        ori_w = float(orientation.find('w').text)

        alignment_poses.append(AlignmentPose(
            pos_x, pos_y, pos_z, (ori_x, ori_y, ori_z, ori_w), name))

    return alignment_poses


def plot_pose_collections(ppcs, colors=None, headings=False, size=None):
    """
    ppcs: list of PanoPoseCollection
    headings: boolean (default: False) - plots headings as vectors
    with size 1.
    """
    _, ax = plt.subplots(figsize=size)

    for i, ppc in enumerate(ppcs):
        kwargs = {}
        if colors is not None:
            kwargs['c'] = colors[i]
        ax.scatter(ppc.pos_xs, ppc.pos_ys, **kwargs)

        if headings is True:
            pc_headings = ppc.headings
            xs = np.cos(np.radians(pc_headings))
            ys = np.sin(np.radians(pc_headings))
            ax.quiver(ppc.pos_xs, ppc.pos_ys, xs, ys, color='k')

    ax.axis('equal')

    plt.show()

def plot_pose_collections_3D(ppcs, colors=None, headings=False, size=None):
    """
    ppcs: list of PanoPoseCollection
    headings: boolean (default: False) - plots headings as vectors
    with size 1.
    """
    fig = plt.figure()
    ax = fig.add_subplot(projection='3d')

    for i, ppc in enumerate(ppcs):
        kwargs = {}
        if colors is not None:
            kwargs['c'] = colors[i]
        ax.scatter(ppc.pos_xs, ppc.pos_ys, ppc.pos_zs, **kwargs)

        if headings is True:
            pc_headings = ppc.headings
            pc_zenits = ppc.zenits
            xs = np.cos(np.radians(pc_headings))
            ys = np.sin(np.radians(pc_headings))
            zs = np.sin(np.radians(pc_zenits))

            ax.quiver(ppc.pos_xs, ppc.pos_ys,ppc.pos_zs, xs, ys, zs,color='k')

    ax.axis('auto')

    plt.show()
def decode_depthmap(source, resize = True, size = (8192,4096), show = False):
    """
    Function to decode the depthmaps generated by the navvis processing
    source: Location of the PNG files containing the depthmap
    resize(bool): If the resulting dethmap needs to be resized to match the size of the corresponding pano, by default True
    size: size of the corresponding pano, by default 8192x4096
    show: if true the result wil be shown, by default False
    """
    depthmap = np.asarray(Image.open(source)).astype(float)
    converted_depthmap = np.empty([np.shape(depthmap)[0], np.shape(depthmap)[1]])
    r = 0
    while r < np.shape(depthmap)[0]:
        c = 0
        while c < np.shape(depthmap)[1]:
            value = depthmap[r,c]
            depth_value = value[0] / 256 * 256 + value[1] / 256 * 256 * 256 + value[2] / 256 * 256 * 256 * 256 + value[3] / 256 * 256 * 256 * 256 * 256
            converted_depthmap[r,c] = depth_value
            c = c + 1
        r = r + 1
    if resize:
        resized_depthmap = cv2.resize(converted_depthmap,size)
        if show:
            plt.imshow(resized_depthmap, cmap="plasma")
            plt.show()
        return resized_depthmap
    else:
        if show:
            plt.imshow(converted_depthmap, cmap="plasma")
            plt.show()
        return converted_depthmap

def get_loaclasses_from_ifcclass(ifcClass:str)->URIRef:
    """ Return the matching LOA class given a ifcClass e.g. IfcWall -> URIRef('https://B2010_EXTERIOR_WALLS').
    The returned subjects can be used to retreive the LOAm and LOAr values from the LOA graph.  

    Args:
        ifcClass (str): class names e.g. IfcWall

    Returns:
        URIRef: subjects of LOA graph 
    """
    if (ifcClass == 'IfcFooting' or
        ifcClass == 'IfcPile' or
        ifcClass == 'IfcPlate'):
        return URIRef('https://A_SUBSTRUCTURE')
    if (ifcClass == 'IfcWall' or
        ifcClass == 'IfcCurtainWall' or
        ifcClass == 'IfcWallStandardCase'):
        return URIRef('https://B2010_EXTERIOR_WALLS')
    if (ifcClass == 'IfcBuildingElement' or
        ifcClass == 'IfcSite' or
        ifcClass == 'IfcBuilding'):
        return URIRef('https://B_SHELL')
    if (ifcClass == 'IfcRoof'):
        return URIRef('https://B1020_ROOF_CONSTRUCTION')
    if (ifcClass == 'IfcSlab'):
        return URIRef('https://B1010_FLOOR_CONSTRUCTION')
    if (ifcClass == 'IfcBuildingStorey'or 
        ifcClass == 'IfcSpace' or
        ifcClass == 'IfcSpatialZone' ):
        return URIRef('https://C_INTERIORS')
    if (ifcClass == 'IfcWindow'):
        return URIRef('https://B2020_EXTERIOR_WINDOWS')
    if (ifcClass == 'IfcRailing'or 
        ifcClass == 'IfcStair' or
        ifcClass == 'IfcStairFlight' ):
        return URIRef('https://B1080_STAIRS')
    if (ifcClass == 'IfcDoor'):
        return URIRef('https://B2020_EXTERIOR_WINDOWS')
    if (ifcClass == 'IfcOpening'):
        return URIRef('https://B3060_HORIZONTAL_OPENINGS')
    if (ifcClass == 'IfcCeiling'):
        return URIRef('https://C1070_SUSPENDED_CEILING_CONSTRUCTION')

    return URIRef('https://C_INTERIORS')


def get_ifcclasses_from_loaclass(loaClass:str)->Literal:
    """_summary_

    Args:
        loaClass (str): _description_

    Returns:
        Literal: _description_
    """
    #A-SUBSTRUCTURE
    if (loaClass == 'A_SUBSTRUCTURE' or 
        loaClass == 'A10_FOUNDATIONS' or 
        loaClass == 'A1010_STANDARD_FOUNDATIONS' or 
        loaClass == 'A1020_SPECIAL_FOUNDATIONS'):
        return Literal(['IfcFooting','IfcPile','IfcPlate'])
    if (loaClass == 'A20_SUBGRADE_ENCLOSURES' or 
        loaClass == 'A2010_WALLS_FOR_SUBGRADE_ENCLOSURES'):
        return Literal(['IfcFooting','IfcPile','IfcPlate','IfcWall','IfcCurtainWall'])
    if (loaClass == 'A40_SLABS_ON_GRADE' or 
        loaClass == 'A4010_STANDARD_SLABS_ON_GRADE' or
        loaClass == 'A4020_STRUCTURAL_SLABS_ON_GRADE' ):
        return Literal(['IfcSlab'])
    
    #B-SHELL
    if (loaClass == 'B_SHELL'  ):
        return Literal(['IfcBuildingElement','IfcSite','IfcRoof','IfcBuildingStorey','IfcSpace','IfcBuilding','IfcBuildingElementProxy','IfcSpatialZone','IfcExternalSpatialStructureElement'])
    if loaClass == 'B10_SUPERSTRUCTURE':
        return Literal(['IfcBuildingElement','IfcBuildingStorey','IfcSpace','IfcBuilding','IfcBuildingElementProxy','IfcSpatialZone'])
    if loaClass == 'B1010_FLOOR_CONSTRUCTION':
        return Literal(['IfcSlab'])
    if loaClass == 'B1020_ROOF_CONSTRUCTION':
        return Literal(['IfcRoof'])
    if loaClass == 'B1080_STAIRS':
        return Literal(['IfcRailing','IfcStair','IfcStairFlight'])
    if loaClass == 'B20_EXTERIOR_VERTICAL_ENCLOSURES':
        return Literal(['IfcWall','IfcWindow','IfcDoor','IfcChimney','IfcCurtainWall','IfcWallStandardCase'])
    if (loaClass == 'B2010_EXTERIOR_WALLS' or
        loaClass == 'B2080_EXTERIOR_WALLS_AND_APPURTENANCES' or
        loaClass == 'B2090_EXTERIOR_WALLS_SPECIALTIES' ):
        return Literal(['IfcWall','IfcCurtainWall','IfcWallStandardCase'])
    if loaClass == 'B2020_EXTERIOR_WINDOWS':
        return Literal(['IfcWindow'])
    if loaClass == 'B2050_EXTERIOR_DOORS_AND_GRILLES':
        return Literal(['IfcDoor'])
    if loaClass == 'B30_EXTERIOR_HORIZONTAL_ENCLOSURES':
        return Literal(['IfcSlab','IfcRoof'])
    if (loaClass == 'B3010_ROOFING' or
        loaClass ==  'B3020_ROOF_APPERURTENANCES'):
        return Literal(['IfcRoof'])
    if loaClass == 'B3040_TRAFFIC_BEARING_HORIZONTAL_ENCLOSURES':
        return Literal(['IfcSlab'])
    if loaClass == 'B3060_HORIZONTAL_OPENINGS':
        return Literal(['IfcOpening'])
    if loaClass == 'B3080_OVERHEAD_EXTERIOR_ENCLOSURES':
        return Literal(['IfcSlab','IfcCeiling','IfcCovering'])
    
    #C-INTERIOR
    if loaClass == 'C_INTERIORS':
        return Literal(['IfcFurniture','IfcCeiling','IfcDoor','IfcWindow','IfcWall'])
    if loaClass == 'C10_INTERIOR_CONSTRUCTION':
        return Literal(['IfcFurniture','IfcCeiling','IfcDoor','IfcWindow','IfcWall'])
    if loaClass == 'C1010_INTERIOR_PARTITIONS':
        return Literal(['IfcRoom','IfcSpace'])
    if loaClass == 'C1020_INTERIOR_WINDOWS':
        return Literal(['IfcWindow'])
    if loaClass == 'C1030_INTERIOR_DOORS':
        return Literal(['IfcDoor'])
    if loaClass == 'C1040_INTERIOR_GRILLES_AND_GATES':
        return Literal(['IfcFurniture'])
    if loaClass == 'C1060_RAISED_FLOOR_CONSTRUCTION':
        return Literal(['IfcSlab'])
    if loaClass == 'C1070_SUSPENDED_CEILING_CONSTRUCTION':
        return Literal(['IfcCeiling'])
    if loaClass == 'C1090_INTERIOR_SPECIALTIES':
        return Literal(['IfcFurniture'])
    if loaClass == 'C20_INTERIOR_FINISHES':
        return Literal(['IfcFurniture'])
    if loaClass == 'C2010_WALL_FINISHES':
        return Literal(['IfcWall','IfcCurtainWall'])
    if loaClass == 'C2020_INTERIOR_FABRICATIONS':
        return Literal(['IfcFurniture'])
    if loaClass == 'C2030_FLOORING':
        return Literal(['IfcSlab'])
    if loaClass == 'C2040_STAIR_FINISHES':
        return Literal(['IfcRailing'])
    if loaClass == 'C2050_CEILING_FINISHES':
        return Literal(['IfcCeiling'])
    
    return Literal(['IfcBuildingElement'])

def create_default_loa_graph(path:str=None)->Graph:
    """Generates a Graph from the default USIBD_SPC-LOA_C220_2016_ver0_1 specification. This specification contains information on the accuraycy
    of building documentation and representation. \n

    Example:

        <https://A1010_STANDARD_FOUNDATIONS> a "LOA" ;\n
        ifc:classes "['IfcFooting', 'IfcPile', 'IfcPlate']" ;\n
        loa:CSI "A1010" ;\n
        loa:LOAm 10 ;\n
        loa:LOAr 20 ;\n
        loa:validation "B" .\n

    More documentation can be found on https://docplayer.net/131921614-Usibd-level-of-accuracy-loa-specification-guide.html# on how to use this specification.

    Args:
        path (str, optional): path to CSV with USIBD values

    Returns:
        Graph: graph with serialized accuracies, to be used in validation procedures
    """
    path=Path(path)
    #load default dataframe
    if not path:
        path=os.path.join(os.path.abspath(os.path.join(os.getcwd(), os.pardir)),"geomapi",'tools','validationtools','LOA.csv')
    LOAdataFrame = pd.read_csv(path,
                        sep=';')
    graph=Graph()
    graph=ut.bind_ontologies(graph)        
    graph.bind('loa', loa)    
    for index,row in LOAdataFrame.iterrows():
        subject=URIRef('https://'+row[0])
        graph.add((subject, RDF.type, Literal('LOA') ))  
        graph.add((subject, loa['CSI'], Literal(row[1]) ))  
        graph.add((subject, loa['LOAm'], Literal(row[2]) ))  
        graph.add((subject, loa['LOAr'], Literal(row[3]) ))  
        graph.add((subject, loa['validation'], Literal(row[4]) )) 
        graph.add((subject, ifc['classes'], get_ifcclasses_from_loaclass(row[0]))) 
    return graph

def parse_loa_excel(path:str) -> Graph:
    """Parse an USIBD_SPC-LOA_C220_2016_ver0_1.xlsx spreadsheet that contains meaured/represented accuracy parameters for building documentation procedures.
    The returned graph can be used by GEOMAPI or other linked data processes to validate remote sensing/BIM models. \n

    More documentation can be found on https://docplayer.net/131921614-Usibd-level-of-accuracy-loa-specification-guide.html# on how to use this specification.
    If no excel is presented, a graph with standard values will be obtained.

    .. image:: ../../../docs/pics/USIBD.PNG

    Args:
        excelPath (str): file path to the spreadsheet

    Returns:
        Graph: graph 
    """
    path=Path(path)
    #read standard LOA graph
    graph=Graph().parse(os.path.join(os.path.abspath(os.path.join(os.getcwd(), os.pardir)),"geomapi",'tools','validationtools','loaGraph.ttl')) 
    subjects=[s for s in graph.subjects(RDF.type)]

    #read excel
    dataFrame = pd.read_excel(path,
                    header=None,
                    na_filter=False)

    #change LOA graph
    for index, row in dataFrame.iterrows():
        #get excell name
        s=None
        if row[3]:
            s=row[3]
        elif row[2]:
            s=row[2]            
        elif row[1]:
            s=row[1]       
        else:
            continue
        # get corresponding subject
        list=[subject for subject in subjects if re.search(s, subject, re.IGNORECASE)]
     
        if len(list)>0:
            subject=subjects[0]
        else:
            continue

        # modify graph LOAm value
        list=[(i+1)*10 for i,value in enumerate(row[5:9]) if value]          
        if len(list)>0:
            graph.set((subject,loa['LOAm'], Literal(list[0]) ))
        # modify graph LOAr value
        list=[(i+1)*10 for i,value in enumerate(row[13:17]) if value]           
        if len(list)>0:
            graph.set((subject,loa['LOAr'], Literal(list[0]) ))
        # modify graph validation value
        list=[value for value in [row[10]] if value]            
        if len(list)>0:
            graph.set((subject,loa['validation'], Literal(list[0]) ))
    return graph

def get_loa_class_per_bimnode(BIMNodes:List[BIMNode] , path:str=None):
    """Assigns the accuracy properties of an LOA Excel spreadsheet to the list of BIMNodes. 
    The assignment is based on the ifc classNames which are mapped to LOA classes. 

    Features:
        1. LOAm (measured accuracy)
        2. LOAr (represented accuracy)
        3. validation (A, B or C)

    Args:
        BIMNodes (List[BIMNode]): List of nodes to assign the propteries to. 
        path (str, optional): Path to Excel spreadsheet. If None, the default LOA properties are assigned.
    """
    path=Path(path)
    #parse Excel if present
    loaGraph=parse_loa_excel(path)

    #assign LOA properties
    for n in BIMNodes:
        loaClass=get_loaclasses_from_ifcclass(n.className)
        for p,o in loaGraph.predicate_objects(subject=loaClass):
            attr= ut.get_attribute_from_predicate(loaGraph, p) 
            if attr not in ['classes','type']:
                setattr(n,attr,o.toPython()) 
