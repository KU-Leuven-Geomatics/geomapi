{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Volume calculation\n",
    "\n",
    "Progress monitoring of construction sites is becoming increasingly popular in the construction industry. Especially with the integration of 4D BIM, the progression and quality of the construction process can be better quantified. A key aspect is the detection of the changes between consecutive epochs of measurements on the site. However, the development of automated procedures is challenging due to noise, occlusions and the associativity between different objects. The focus here will be on volume calculations between two epochs. In extension the volume between an epoch and a as-deign model will be calculated. This is the first step to progress monitoring the site for quantity take-offs.\n",
    "\n",
    "\n",
    "In this testcase, we will discuss how to use GEOMAPI to assess progress on a typical BIM-driven construction site. Concretely, we will demonstrate the API's functionality to:\n",
    "1. Preprocess the BIM data from multiple IFC files\n",
    "2. Preprocess the various remote sensing data (images, meshes, point clouds) of two measurement epochs\n",
    "3. Make a subselection of observable objects\n",
    "4. Determine the volume of the observable objects\n",
    "5. Serialize the analysis results\n",
    "6. Use the resulting RDF Graph of epoch 1 to support the analysis of epoch 2.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "from rdflib import Graph, plugin\n",
    "import uuid    \n",
    "import importlib\n",
    "import PIL.Image as PILimage\n",
    "import os.path\n",
    "import open3d   as o3d\n",
    "import trimesh\n",
    "import cv2\n",
    "import xml.etree.ElementTree as ET \n",
    "import numpy as np\n",
    "from rdflib import URIRef\n",
    "#IMPORT MODULES\n",
    "from context import geomapi \n",
    "from geomapi.nodes import *\n",
    "import geomapi.utils as ut\n",
    "from geomapi.utils import geometryutils as gmu\n",
    "import geomapi.tools as tl\n",
    "from geomapi.tools import validationtools as vt\n",
    "import geomapi.tools.progresstools as pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We select the right projectpath for the rest of the rest of the testcase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "projectPath= \"C:\\RepoHeinder\\geomapi\\developmenttests\\Sample4\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BIM Model\n",
    "The dataset that will be used for this analysis is a road with some enviremantal accents such as trees and a ditch. Fig. 1 shows the ifc file of the road construction site. First we will create BIM Nodes from the entire IFC file. Following the GEOMAPI principles, we serialize all relevent objects in the BIM model to an RDF Graph. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![rendering](../../pics/BIM1.PNG)\n",
    "**Fig.1**: Road construction site: IFC file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the BIM Model\n",
    "Following the GEOMAPI principles, we serialize all relevent objects in the BIM model to an RDF Graph.For this analysis, we parse the ifc files using all CPU's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\RepoHeinder\\geomapi\\developmenttests\\Sample4\\Mariakerke_AWV_Conform_3D_BT_l72.ifc\n"
     ]
    }
   ],
   "source": [
    "ifcPath = os.path.join(projectPath ,'Mariakerke_AWV_Conform_3D_BT_l72.ifc') \n",
    "print(ifcPath)\n",
    "bimNodes=tl.ifc_to_nodes_multiprocessing(ifcPath)\n",
    "bimNodes=[n for n in bimNodes if n.resource]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in bimNodes:\n",
    "    node.name=node.subject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is not uncommon for certain elements to not have geometry or have some invalid meshes. These will yield **Geometry Production Errors**.\n",
    "\n",
    "We visualize the ifc model with open 3d."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bimgeometries=[n.resource for n in bimNodes if n.resource]\n",
    "o3d.visualization.draw_geometries(bimgeometries)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When looking at the instance variables of one of the BIMNodes, it is revealed that GEOMAPI has indeed gathered all the relevant metadata for geomatic analysis of the objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_ifcPath': 'C:\\\\RepoHeinder\\\\geomapi\\\\developmenttests\\\\Sample4\\\\Mariakerke_AWV_Conform_3D_BT_l72.ifc',\n",
       " '_globalId': '1o3B_qZ1zDJ8f$yWqBiQOZ',\n",
       " '_cartesianBounds': array([1.00576881e+05, 1.00579115e+05, 1.96310389e+05, 1.96312474e+05,\n",
       "        5.46586985e+00, 6.56586985e+00]),\n",
       " '_orientedBounds': array([[1.00577661e+05, 1.96309979e+05, 5.56611876e+00],\n",
       "        [1.00579485e+05, 1.96311006e+05, 5.75898376e+00],\n",
       "        [1.00576874e+05, 1.96311527e+05, 4.77447267e+00],\n",
       "        [1.00577311e+05, 1.96310386e+05, 6.71038408e+00],\n",
       "        [1.00578348e+05, 1.96312961e+05, 6.11160300e+00],\n",
       "        [1.00576524e+05, 1.96311934e+05, 5.91873799e+00],\n",
       "        [1.00579135e+05, 1.96311414e+05, 6.90324908e+00],\n",
       "        [1.00578698e+05, 1.96312554e+05, 4.96733768e+00]]),\n",
       " '_orientedBoundingBox': OrientedBoundingBox: center: (100578, 196311, 5.83886), extent: 2.10216, 1.90812, 1.26405),\n",
       " '_subject': rdflib.term.URIRef('file:///BT3_Waterbouwkundige_Constructie_KNW2_1o3B_qZ1zDJ8f_yWqBiQOZ'),\n",
       " '_graph': None,\n",
       " '_graphPath': None,\n",
       " '_path': None,\n",
       " '_name': 'file:///BT3_Waterbouwkundige_Constructie_KNW2_1o3B_qZ1zDJ8f_yWqBiQOZ',\n",
       " '_timestamp': '2022-11-17T09:43:28',\n",
       " '_resource': TriangleMesh with 149 points and 302 triangles.,\n",
       " '_cartesianTransform': array([[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00577790e+05],\n",
       "        [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 1.96311741e+05],\n",
       "        [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 5.91418604e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00]]),\n",
       " 'className': 'IfcSite',\n",
       " 'pointCount': 149,\n",
       " 'faceCount': 302}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{key:value for key, value in bimNodes[0].__dict__.items() if not key.startswith('__') and not callable(key)}              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can buffer these geometries on drive so we only have to parse the ifc file once. We can then reload these geometries to assess the other flight data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder=os.path.join(projectPath,'myAnalysisFolder')\n",
    "if not os.path.exists(folder):\n",
    "    os.mkdir(folder)\n",
    "\n",
    "for node in bimNodes:\n",
    "    node.save_resource(os.path.join(folder,'BIM'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This also sets the path of each node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/RepoHeinder/geomapi/developmenttests/Sample4/myAnalysisFolder/BIM/BT3_Waterbouwkundige_Constructie_KNW2_1o3B_qZ1zDJ8f_yWqBiQOZ.ply\n"
     ]
    }
   ],
   "source": [
    "print(bimNodes[0].path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is good practice to already serialize these nodes in a RDF graph so we can rapidly load the nodes from the graphs in a next code run. In this testcase, we will store the generated graph in the same location as the buffered mesh geometries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N2c91d99111954fff81bf35371c4d2f0f (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphPath=os.path.join(projectPath,'myAnalysisFolder','BIM','bimGraph.ttl')\n",
    "tl.nodes_to_graph(nodelist=bimNodes,graphPath=graphPath,save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sets each BIMNodes' graphpath and graph. The graph of BIMNodes[0] then looks as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/RepoHeinder/geomapi/developmenttests/Sample4/myAnalysisFolder/BIM/bimGraph.ttl\n",
      "@prefix e57: <http://libe57.org#> .\n",
      "@prefix ifc: <http://ifcowl.openbimstandards.org/IFC2X3_Final#> .\n",
      "@prefix openlabel: <https://www.asam.net/index.php?eID=dumpFile&t=f&f=3876&token=413e8c85031ae64cc35cf42d0768627514868b2f#> .\n",
      "@prefix v4d: <https://w3id.org/v4d/core#> .\n",
      "@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\n",
      "\n",
      "<file:///BT3_Waterbouwkundige_Constructie_KNW2_1o3B_qZ1zDJ8f_yWqBiQOZ> a v4d:BIMNode ;\n",
      "    ifc:className \"IfcSite\" ;\n",
      "    ifc:globalId \"1o3B_qZ1zDJ8f$yWqBiQOZ\" ;\n",
      "    ifc:ifcPath \"..\\\\..\\\\Mariakerke_AWV_Conform_3D_BT_l72.ifc\" ;\n",
      "    e57:cartesianBounds \"\"\"[1.00576881e+05 1.00579115e+05 1.96310389e+05 1.96312474e+05\n",
      " 5.46586985e+00 6.56586985e+00]\"\"\" ;\n",
      "    e57:cartesianTransform \"\"\"[[1.00000000e+00 0.00000000e+00 0.00000000e+00 1.00577790e+05]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 1.96311741e+05]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00 5.91418604e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00]]\"\"\" ;\n",
      "    e57:pointCount 149 ;\n",
      "    v4d:faceCount 302 ;\n",
      "    v4d:name \"file:///BT3_Waterbouwkundige_Constructie_KNW2_1o3B_qZ1zDJ8f_yWqBiQOZ\" ;\n",
      "    v4d:orientedBounds \"\"\"[[1.00577661e+05 1.96309979e+05 5.56611876e+00]\n",
      " [1.00579485e+05 1.96311006e+05 5.75898376e+00]\n",
      " [1.00576874e+05 1.96311527e+05 4.77447267e+00]\n",
      " [1.00577311e+05 1.96310386e+05 6.71038408e+00]\n",
      " [1.00578348e+05 1.96312961e+05 6.11160300e+00]\n",
      " [1.00576524e+05 1.96311934e+05 5.91873799e+00]\n",
      " [1.00579135e+05 1.96311414e+05 6.90324908e+00]\n",
      " [1.00578698e+05 1.96312554e+05 4.96733768e+00]]\"\"\" ;\n",
      "    v4d:path \"BT3_Waterbouwkundige_Constructie_KNW2_1o3B_qZ1zDJ8f_yWqBiQOZ.ply\" ;\n",
      "    openlabel:timestamp \"2022-11-17T09:43:28\" .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(bimNodes[0].graphPath)\n",
    "print(bimNodes[0].graph.serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** that all path triples in graph are serialized relative to the graphPath so to make it easier to move the entire folderstructure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reloading from graph\n",
    "The above steps only have to be performed once. On reruns of the code or future analysis, we can initialize the same nodes from their serialized triples in the bimGraph. This is significantly faster for smaller graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "graphPath=os.path.join(projectPath,'myAnalysisFolder','BIM','bimGraph.ttl')\n",
    "bimNodes=tl.graph_path_to_nodes(graphPath=graphPath,getResource=True)\n",
    "print(len(bimNodes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flight data\n",
    "We will evaluate two flights captured in two exacutive weeks on the site. 101_0365 is captured the last week of may, 101_0366 is captured the first week of June. This data is captured with the RTK-Drone (DJI Phantom 4, RTK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flight 101_0366\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess measurements flight 101_0366\n",
    "Data of flight 101_0366 will be imported as part of a SessionNode. This sessionNode contains the individual Nodes of each of the resources and also some general metadata. \n",
    "\n",
    "First, we parse each set of resources (1 point cloud, 56 Images and the photogrammetric mesh).\n",
    "\n",
    "**NOTE**: This is alot of data, some of which we potentially don't need as observable objects might not be located within the sensors Field-of-View. GEOMAPI plans for this, and allows Node metadata initialisation from other sources but the actual data such as image metadata files, e57 headers, etc. The actual resources that are needed can be imported at a later stage through get_resource() methods. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fig.2**: Road construction site: mesh of flight 101_0366 . \n",
    "![rendering](../../pics/Mesh101_0366_meshlab.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **E57 POINT CLOUDS**: These nodes from the e57 header instead of actually importing the data so a first spatial analysis can be conducted effeciently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_e57Index': 0,\n",
       " 'pointCount': 6784867,\n",
       " 'e57XmlPath': None,\n",
       " '_cartesianBounds': array([1.00552700e+05, 1.00634825e+05, 1.96220530e+05, 1.96326367e+05,\n",
       "        5.05700000e+00, 8.25700000e+00]),\n",
       " '_orientedBounds': None,\n",
       " '_orientedBoundingBox': None,\n",
       " '_subject': rdflib.term.URIRef('file:///PCDLAMBERT72_TAW'),\n",
       " '_graph': <Graph identifier=N4ea4c35b86e740c4a7dbea4275c5f9fc (<class 'rdflib.graph.Graph'>)>,\n",
       " '_graphPath': 'O:\\\\Code\\\\geomapi\\\\developmenttests\\\\Sample4\\\\myAnalysisFolder\\\\PCD\\\\pcdGraph101_0366.ttl',\n",
       " '_path': 'O:\\\\Code\\\\geomapi\\\\developmenttests\\\\Sample4\\\\Pointclouds\\\\101_0366\\\\PCDLAMBERT72_TAW.e57',\n",
       " '_name': 'PCDLAMBERT72_TAW',\n",
       " '_timestamp': '2022-07-19T15:51:08',\n",
       " '_resource': None,\n",
       " '_cartesianTransform': None}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e57Path=os.path.join(projectPath ,'Pointclouds','101_0366','PCDLAMBERT72_TAW.e57')\n",
    "pcdNodes=tl.e57header_to_nodes(e57Path)\n",
    "#serialize nodes\n",
    "folder=os.path.join(projectPath,'myAnalysisFolder','PCD')\n",
    "if not os.path.exists(folder):\n",
    "    os.mkdir(folder)\n",
    "graphPath=os.path.join(projectPath,'myAnalysisFolder','PCD','pcdGraph101_0366.ttl')\n",
    "tl.nodes_to_graph(nodelist=pcdNodes,graphPath=graphPath,save=True)\n",
    "{key:value for key, value in pcdNodes[0].__dict__.items() if not key.startswith('__') and not callable(key)} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Geolocated Images**: Analogue to the point cloud data, the ImageNodes are initialised from a  Metashape .xml file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_xmlPath': 'O:/Code/geomapi/developmenttests/Sample4/Photos/101_0366/ReferenceLAMBERT72_TAW.xml',\n",
       " '_xmpPath': None,\n",
       " '_orientedBoundingBox': None,\n",
       " 'imageWidth': 5472,\n",
       " 'imageHeight': 3648,\n",
       " 'focalLength35mm': None,\n",
       " '_subject': rdflib.term.URIRef('file:///101_0366_0001'),\n",
       " '_graph': <Graph identifier=N0156f2eeacd44625a61e417f246e9ef6 (<class 'rdflib.graph.Graph'>)>,\n",
       " '_graphPath': 'O:\\\\Code\\\\geomapi\\\\developmenttests\\\\Sample4\\\\myAnalysisFolder\\\\Photos\\\\imageGraph101_0366.ttl',\n",
       " '_path': 'O:/Code/geomapi/developmenttests/Sample4/Photos/101_0366/101_0366_0001.jpg',\n",
       " '_name': '101_0366_0001',\n",
       " '_timestamp': '2021-06-07T16:46:33',\n",
       " '_resource': None,\n",
       " '_cartesianTransform': array([[-7.62667168e-01, -6.46788794e-01,  1.74532837e-03,\n",
       "          1.00574925e+05],\n",
       "        [ 6.46789780e-01, -7.62668330e-01,  0.00000000e+00,\n",
       "          1.96307775e+05],\n",
       "        [ 1.33110667e-03,  1.12886055e-03,  9.99998477e-01,\n",
       "          3.14713656e+01],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          1.00000000e+00]]),\n",
       " 'sxy': 0.02,\n",
       " 'sz': 0.05,\n",
       " 'resolutionUnit': 2,\n",
       " 'geospatialTransform': [51.07479236114782,\n",
       "  3.6635201667228112,\n",
       "  74.20500001762274],\n",
       " 'coordinateSystem': 'geospatial-wgs84'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder=os.path.join(projectPath,'myAnalysisFolder','Photos') \n",
    "if not os.path.exists(folder):\n",
    "    os.mkdir(folder)\n",
    "graphPath=os.path.join(projectPath,'myAnalysisFolder','Photos','imageGraph101_0366.ttl') \n",
    "photoPath = os.path.join(projectPath ,'Photos','101_0366')\n",
    "allSessionFilePaths=ut.get_list_of_files(photoPath) \n",
    "nodelist=[]\n",
    "\n",
    "for path in allSessionFilePaths:        \n",
    "    \n",
    "    if path.endswith(\".JPG\") or path.endswith(\".PNG\"): \n",
    "        testXmpPath=path.replace('JPG','xmp')\n",
    "        if testXmpPath in allSessionFilePaths:\n",
    "            nodelist.append(ImageNode(path=path,xmpPath=testXmpPath,sessionPath=photoPath))\n",
    "            # tl.nodes_to_graph(nodelist=imageNode,graphPath=graphPath,save=True)\n",
    "            # {key:value for key, value in pcdNodes[0].__dict__.items() if not key.startswith('__') and not callable(key)} \n",
    "        else:\n",
    "            nodelist.append(ImageNode(path=path,sessionPath=photoPath))\n",
    "            # tl.nodes_to_graph(nodelist=imageNode,graphPath=graphPath,save=True)\n",
    "            # {key:value for key, value in pcdNodes[0].__dict__.items() if not key.startswith('__') and not callable(key)} \n",
    "\n",
    "    if path.endswith(\".xml\"):\n",
    "        nodelist.extend(tl.img_xml_to_nodes(path, getResource=True,graphPath=graphPath))\n",
    "\n",
    "imageNode=tl.img_xml_to_nodes(path)\n",
    "tl.nodes_to_graph(nodelist=imageNode,graphPath=graphPath,save=True)\n",
    "{key:value for key, value in imageNode[0].__dict__.items() if not key.startswith('__') and not callable(key)}         \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Photogrammetric mesh**: Mesh files have no metadata headers so the data has to be loaded by GEOMAPI. However, to save memory (and to illustrate the non-data functionality), we will discard the data as soon as the relevant metadata is extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pointCount': 274850,\n",
       " 'faceCount': 545530,\n",
       " '_cartesianBounds': array([1.00551838e+05, 1.00635544e+05, 1.96219581e+05, 1.96327133e+05,\n",
       "        5.13973500e+00, 8.25403600e+00]),\n",
       " '_orientedBounds': array([[1.00601668e+05, 1.96334413e+05, 8.26347399e+00],\n",
       "        [1.00643307e+05, 1.96235497e+05, 8.51657553e+00],\n",
       "        [1.00543892e+05, 1.96310092e+05, 8.09708756e+00],\n",
       "        [1.00601679e+05, 1.96334410e+05, 5.14167178e+00],\n",
       "        [1.00585541e+05, 1.96211172e+05, 5.22838689e+00],\n",
       "        [1.00543903e+05, 1.96310089e+05, 4.97528536e+00],\n",
       "        [1.00643317e+05, 1.96235493e+05, 5.39477332e+00],\n",
       "        [1.00585530e+05, 1.96211176e+05, 8.35018910e+00]]),\n",
       " '_orientedBoundingBox': OrientedBoundingBox: center: (100594, 196273, 6.74593), extent: 107.323, 62.6867, 3.12182),\n",
       " '_subject': rdflib.term.URIRef('file:///1010366'),\n",
       " '_graph': <Graph identifier=N5130223137f84d42818ecbe04dba602b (<class 'rdflib.graph.Graph'>)>,\n",
       " '_graphPath': 'O:\\\\Code\\\\geomapi\\\\developmenttests\\\\Sample4\\\\myAnalysisFolder\\\\Meshes\\\\meshGraph101_0366.ttl',\n",
       " '_path': 'O:\\\\Code\\\\geomapi\\\\developmenttests\\\\Sample4\\\\Meshes\\\\101_0366\\\\MeshLAMBERT72_TAW.ply',\n",
       " '_name': 'MeshLAMBERT72_TAW',\n",
       " '_timestamp': '2022-09-16T17:35:08',\n",
       " '_resource': TriangleMesh with 274850 points and 545530 triangles.,\n",
       " '_cartesianTransform': array([[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00593782e+05],\n",
       "        [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 1.96271358e+05],\n",
       "        [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 6.37094559e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00]])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meshPath = os.path.join(projectPath ,'Meshes','101_0366','MeshLAMBERT72_TAW.ply')\n",
    "texturepath=os.path.join(projectPath ,'Meshes','101_0366','MeshLAMBERT72_TAW.jpg')\n",
    "meshNode= MeshNode(subject=101_0366,path=meshPath,getResource=True)\n",
    "\n",
    "#serialize nodes\n",
    "folder=os.path.join(projectPath ,'myAnalysisFolder','Meshes')\n",
    "if not os.path.exists(folder):\n",
    "    os.mkdir(folder)\n",
    "graphPath=os.path.join(projectPath ,'myAnalysisFolder','Meshes','meshGraph101_0366.ttl')\n",
    "meshNode.to_graph(graphPath=graphPath,save=True)\n",
    "{key:value for key, value in meshNode.__dict__.items() if not key.startswith('__') and not callable(key)}     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SessionNode\n",
    "From the above nodes, a overarching session can be created. As such, 2 sessions are created, one for each meaurement epoch.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n",
      "file:///101_0366\n"
     ]
    }
   ],
   "source": [
    "linkedNodes=pcdNodes + imageNode + [meshNode]\n",
    "sess101_0366=SessionNode(subject='101_0366', linkedNodes=linkedNodes)\n",
    "print(len(sess101_0366.linkedNodes))\n",
    "print(sess101_0366.subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess101_0366.save_resource(os.path.join(projectPath ,'myAnalysisFolder'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fig.3**: (red) orientedBoundingBoxes of the pcdNodes and the meshNode, (red cones) scaled img field-of-views and (green) convex hull of the sessionNode.\n",
    "![rendering](../../pics/101_0365_overview.JPG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcdboxes=[n.get_oriented_bounding_box() for n in pcdNodes ]\n",
    "for box in pcdboxes:\n",
    "    box.color=[1,0,0]\n",
    "# print(len(pcdboxes))\n",
    "\n",
    "imggeometries=[n.get_mesh_geometry(depth=2) for n in imageNode ]\n",
    "[img.paint_uniform_color([1,0,0]) for img in imggeometries]\n",
    "# print(len(imggeometries))\n",
    "\n",
    "meshbox=meshNode.get_oriented_bounding_box()\n",
    "meshbox.color=[1,0,0]\n",
    "# print(len([meshbox]))\n",
    "\n",
    "lineset1=o3d.geometry.LineSet.create_from_triangle_mesh(sess101_0366.resource)\n",
    "lineset1.paint_uniform_color([0,1,0])\n",
    "# print(len([lineset1]))\n",
    "\n",
    "\n",
    "mesh=o3d.io.read_triangle_mesh(meshPath)\n",
    "mesh.paint_uniform_color([1, 0.706, 0])\n",
    "mesh.compute_vertex_normals()\n",
    "\n",
    "\n",
    "o3d.visualization.draw_geometries( imggeometries + [meshbox] + [lineset1] + [mesh] + bimgeometries ) #,lineset1,meshbox,imggeometries\n",
    "\n",
    "\n",
    "# print(len(geometries))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is good practice to already serialize these nodes in a RDF graph so we can rapidly load the nodes from the graphs in a next run. The facilitate the datastructure, we will store the generated graph in the same location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@prefix e57: <http://libe57.org#> .\n",
      "@prefix openlabel: <https://www.asam.net/index.php?eID=dumpFile&t=f&f=3876&token=413e8c85031ae64cc35cf42d0768627514868b2f#> .\n",
      "@prefix v4d: <https://w3id.org/v4d/core#> .\n",
      "\n",
      "<file:///101_0366> a v4d:SessionNode ;\n",
      "    e57:cartesianBounds \"\"\"[1.00543892e+05 1.00643317e+05 1.96211172e+05 1.96334413e+05\n",
      " 4.97528536e+00 3.14892832e+01]\"\"\" ;\n",
      "    e57:cartesianTransform \"\"\"[[1.00000000e+00 0.00000000e+00 0.00000000e+00 1.00593672e+05]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 1.96269668e+05]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00 2.57391447e+01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00]]\"\"\" ;\n",
      "    v4d:linkedSubjects \"['file:///PCDLAMBERT72_TAW', 'file:///101_0366_0001', 'file:///101_0366_0002', 'file:///101_0366_0003', 'file:///101_0366_0004', 'file:///101_0366_0005', 'file:///101_0366_0006', 'file:///101_0366_0007', 'file:///101_0366_0008', 'file:///101_0366_0009', 'file:///101_0366_0010', 'file:///101_0366_0011', 'file:///101_0366_0012', 'file:///101_0366_0013', 'file:///101_0366_0014', 'file:///101_0366_0015', 'file:///101_0366_0016', 'file:///101_0366_0017', 'file:///101_0366_0018', 'file:///101_0366_0019', 'file:///101_0366_0020', 'file:///101_0366_0021', 'file:///101_0366_0022', 'file:///101_0366_0023', 'file:///101_0366_0024', 'file:///101_0366_0025', 'file:///101_0366_0026', 'file:///101_0366_0027', 'file:///101_0366_0028', 'file:///101_0366_0029', 'file:///101_0366_0030', 'file:///101_0366_0031', 'file:///101_0366_0032', 'file:///101_0366_0033', 'file:///101_0366_0034', 'file:///101_0366_0035', 'file:///101_0366_0036', 'file:///101_0366_0037', 'file:///101_0366_0038', 'file:///101_0366_0039', 'file:///101_0366_0040', 'file:///101_0366_0041', 'file:///101_0366_0042', 'file:///101_0366_0043', 'file:///101_0366_0044', 'file:///101_0366_0045', 'file:///101_0366_0046', 'file:///101_0366_0047', 'file:///101_0366_0048', 'file:///101_0366_0049', 'file:///101_0366_0050', 'file:///101_0366_0051', 'file:///101_0366_0052', 'file:///101_0366_0053', 'file:///101_0366_0054', 'file:///101_0366_0055', 'file:///101_0366_0056', 'file:///1010366']\" ;\n",
      "    v4d:name \"101_0366\" ;\n",
      "    v4d:orientedBounds \"\"\"[[1.00622442e+05 1.96356505e+05 3.02635884e+01]\n",
      " [1.00673157e+05 1.96237288e+05 3.24867973e+01]\n",
      " [1.00514762e+05 1.96310732e+05 3.20948960e+01]\n",
      " [1.00622222e+05 1.96355876e+05 1.55571535e+00]\n",
      " [1.00565256e+05 1.96190886e+05 5.61023180e+00]\n",
      " [1.00514541e+05 1.96310103e+05 3.38702292e+00]\n",
      " [1.00672937e+05 1.96236659e+05 3.77892423e+00]\n",
      " [1.00565477e+05 1.96191515e+05 3.43181049e+01]]\"\"\" ;\n",
      "    v4d:path \"101_0366.ply\" ;\n",
      "    openlabel:timestamp \"2022-07-19T15:51:08\" .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "graphPath=os.path.join(projectPath ,'myAnalysisFolder','sessionGraph101_0366.ttl')\n",
    "sess101_0366.to_graph(graphPath=graphPath,save=True)\n",
    "print(sess101_0366.graph.serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reloading from graph\n",
    "Similar to the BIM preprocessing, the above steps only have to be performed once. On reruns of the code or future analysis, we can initialize the same nodes from their serialized triples. This is significantly faster for smaller graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n"
     ]
    }
   ],
   "source": [
    "sessionGraphPath=os.path.join(projectPath ,'myAnalysisFolder','sessionGraph101_0366.ttl')\n",
    "week22=SessionNode(graphPath=sessionGraphPath)\n",
    "\n",
    "#get resourceGraphs\n",
    "resourceGraph=Graph().parse(os.path.join(projectPath,'myAnalysisFolder','Photos','imageGraph101_0366.ttl') )\n",
    "resourceGraph+=Graph().parse(os.path.join(projectPath ,'myAnalysisFolder','Meshes','meshGraph101_0366.ttl'))\n",
    "resourceGraph+=Graph().parse(os.path.join(projectPath,'myAnalysisFolder','PCD','pcdGraph101_0366.ttl'))\n",
    "\n",
    "sess101_0366.get_linked_nodes(resourceGraph=resourceGraph)\n",
    "print(len(linkedNodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flight 101_0367\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess measurements flight 101_0367\n",
    "Data of flight 101_0367 will be imported as part of a SessionNode. This sessionNode contains the individual Nodes of each of the resources and also some general metadata. \n",
    "\n",
    "First, we parse each set of resources (1 point cloud, 56 Images and the photogrammetric mesh).\n",
    "\n",
    "**NOTE**: This is alot of data, some of which we potentially don't need as observable objects might not be located within the sensors Field-of-View. GEOMAPI plans for this, and allows Node metadata initialisation from other sources but the actual data such as image metadata files, e57 headers, etc. The actual resources that are needed can be imported at a later stage through get_resource() methods. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fig.4**: Road construction site: Flight 101_0367. \n",
    "![rendering](../../pics/Mesh101_0367_meshlab.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **E57 POINT CLOUDS**: These nodes from the e57 header instead of actually importing the data so a first spatial analysis can be conducted effeciently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_e57Index': 0,\n",
       " 'pointCount': 7062921,\n",
       " 'e57XmlPath': None,\n",
       " '_cartesianBounds': array([1.00552835e+05, 1.00648663e+05, 1.96219459e+05, 1.96324429e+05,\n",
       "        4.85900000e+00, 8.29300000e+00]),\n",
       " '_orientedBounds': None,\n",
       " '_orientedBoundingBox': None,\n",
       " '_subject': rdflib.term.URIRef('file:///PCDLAMBERT72_TAW'),\n",
       " '_graph': <Graph identifier=Nd663af1f21504515a3634f0ad82440a8 (<class 'rdflib.graph.Graph'>)>,\n",
       " '_graphPath': 'O:\\\\Code\\\\geomapi\\\\developmenttests\\\\Sample4\\\\myAnalysisFolder\\\\PCD\\\\pcdGraph101_0367.ttl',\n",
       " '_path': 'O:\\\\Code\\\\geomapi\\\\developmenttests\\\\Sample4\\\\Pointclouds\\\\101_0367\\\\PCDLAMBERT72_TAW.e57',\n",
       " '_name': 'PCDLAMBERT72_TAW',\n",
       " '_timestamp': '2022-07-19T16:21:08',\n",
       " '_resource': None,\n",
       " '_cartesianTransform': None}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e57Path=os.path.join(projectPath ,'Pointclouds','101_0367','PCDLAMBERT72_TAW.e57')\n",
    "pcdNodes=tl.e57header_to_nodes(e57Path)\n",
    "#serialize nodes\n",
    "folder=os.path.join(projectPath,'myAnalysisFolder','PCD')\n",
    "if not os.path.exists(folder):\n",
    "    os.mkdir(folder)\n",
    "graphPath=os.path.join(projectPath,'myAnalysisFolder','PCD','pcdGraph101_0367.ttl')\n",
    "tl.nodes_to_graph(nodelist=pcdNodes,graphPath=graphPath,save=True)\n",
    "{key:value for key, value in pcdNodes[0].__dict__.items() if not key.startswith('__') and not callable(key)} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Geolocated Images**: Analogue to the point cloud data, the ImageNodes are initialised from a  Metashape .xml file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_xmlPath': 'O:/Code/geomapi/developmenttests/Sample4/Photos/101_0367/ReferenceLAMBERT72_TAW.xml',\n",
       " '_xmpPath': None,\n",
       " '_orientedBoundingBox': None,\n",
       " 'imageWidth': 5472,\n",
       " 'imageHeight': 3648,\n",
       " 'focalLength35mm': None,\n",
       " '_subject': rdflib.term.URIRef('file:///101_0367_0001'),\n",
       " '_graph': <Graph identifier=N0bc778a97fbc46aa8e80c1422821d5c8 (<class 'rdflib.graph.Graph'>)>,\n",
       " '_graphPath': 'O:\\\\Code\\\\geomapi\\\\developmenttests\\\\Sample4\\\\myAnalysisFolder\\\\Photos\\\\imageGraph101_0367.ttl',\n",
       " '_path': 'O:/Code/geomapi/developmenttests/Sample4/Photos/101_0367/101_0367_0001.jpg',\n",
       " '_name': '101_0367_0001',\n",
       " '_timestamp': '2021-06-11T10:12:18',\n",
       " '_resource': None,\n",
       " '_cartesianTransform': array([[-8.03856861e-01, -5.94822787e-01,  0.00000000e+00,\n",
       "          1.00574782e+05],\n",
       "        [ 5.94822787e-01, -8.03856861e-01,  0.00000000e+00,\n",
       "          1.96307758e+05],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "          3.13793641e+01],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          1.00000000e+00]]),\n",
       " 'sxy': 0.02,\n",
       " 'sz': 0.05,\n",
       " 'resolutionUnit': 2,\n",
       " 'geospatialTransform': [51.07479219445777,\n",
       "  3.6635181388946036,\n",
       "  74.11300116904444],\n",
       " 'coordinateSystem': 'geospatial-wgs84'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder=os.path.join(projectPath,'myAnalysisFolder','Photos') \n",
    "if not os.path.exists(folder):\n",
    "    os.mkdir(folder)\n",
    "graphPath=os.path.join(projectPath,'myAnalysisFolder','Photos','imageGraph101_0367.ttl') \n",
    "photoPath = os.path.join(projectPath ,'Photos','101_0367')\n",
    "allSessionFilePaths=ut.get_list_of_files(photoPath) \n",
    "nodelist=[]\n",
    "\n",
    "for path in allSessionFilePaths:        \n",
    "    \n",
    "    if path.endswith(\".JPG\") or path.endswith(\".PNG\"): \n",
    "        testXmpPath=path.replace('JPG','xmp')\n",
    "        if testXmpPath in allSessionFilePaths:\n",
    "            nodelist.append(imageNode(path=path,xmpPath=testXmpPath,sessionPath=photoPath))\n",
    "            # tl.nodes_to_graph(nodelist=imageNode,graphPath=graphPath,save=True)\n",
    "            # {key:value for key, value in pcdNodes[0].__dict__.items() if not key.startswith('__') and not callable(key)} \n",
    "        else:\n",
    "            nodelist.append(imageNode(path=path,sessionPath=photoPath))\n",
    "            # tl.nodes_to_graph(nodelist=imageNode,graphPath=graphPath,save=True)\n",
    "            # {key:value for key, value in pcdNodes[0].__dict__.items() if not key.startswith('__') and not callable(key)} \n",
    "\n",
    "    if path.endswith(\".xml\"):\n",
    "        nodelist.extend(tl.img_xml_to_nodes(path, getResource=True,graphPath=graphPath))\n",
    "\n",
    "imageNode=tl.img_xml_to_nodes(path)\n",
    "tl.nodes_to_graph(nodelist=imageNode,graphPath=graphPath,save=True)\n",
    "{key:value for key, value in imageNode[0].__dict__.items() if not key.startswith('__') and not callable(key)}         \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Photogrammetric mesh**: Mesh files have no metadata headers so the data has to be loaded by GEOMAPI. However, to save memory (and to illustrate the non-data functionality), we will discard the data as soon as the relevant metadata is extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pointCount': 301203,\n",
       " 'faceCount': 597197,\n",
       " '_cartesianBounds': array([1.00552016e+05, 1.00648914e+05, 1.96218781e+05, 1.96325156e+05,\n",
       "        5.12620401e+00, 8.28773785e+00]),\n",
       " '_orientedBounds': array([[1.00608922e+05, 1.96336024e+05, 8.63864855e+00],\n",
       "        [1.00650676e+05, 1.96238313e+05, 8.91333762e+00],\n",
       "        [1.00536941e+05, 1.96305263e+05, 8.02514903e+00],\n",
       "        [1.00608950e+05, 1.96336026e+05, 5.27847026e+00],\n",
       "        [1.00578722e+05, 1.96207554e+05, 4.93965981e+00],\n",
       "        [1.00536968e+05, 1.96305265e+05, 4.66497074e+00],\n",
       "        [1.00650704e+05, 1.96238315e+05, 5.55315933e+00],\n",
       "        [1.00578694e+05, 1.96207552e+05, 8.29983810e+00]]),\n",
       " '_orientedBoundingBox': OrientedBoundingBox: center: (100594, 196272, 6.78915), extent: 106.258, 78.2815, 3.36029),\n",
       " '_subject': rdflib.term.URIRef('file:///1010367'),\n",
       " '_graph': <Graph identifier=Nc8a3445d7044432bb456ab8ca856d2a3 (<class 'rdflib.graph.Graph'>)>,\n",
       " '_graphPath': 'O:\\\\Code\\\\geomapi\\\\developmenttests\\\\Sample4\\\\myAnalysisFolder\\\\Meshes\\\\meshGraph101_0367.ttl',\n",
       " '_path': 'O:\\\\Code\\\\geomapi\\\\developmenttests\\\\Sample4\\\\Meshes\\\\101_0367\\\\MeshLAMBERT72_TAW.ply',\n",
       " '_name': 'MeshLAMBERT72_TAW',\n",
       " '_timestamp': '2022-09-16T17:35:08',\n",
       " '_resource': TriangleMesh with 301203 points and 597197 triangles.,\n",
       " '_cartesianTransform': array([[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00594174e+05],\n",
       "        [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 1.96268940e+05],\n",
       "        [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 6.45470017e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00]])}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meshPath = os.path.join(projectPath ,'Meshes','101_0367','MeshLAMBERT72_TAW.ply')\n",
    "texturepath=os.path.join(projectPath ,'Meshes','101_0367','MeshLAMBERT72_TAW.jpg')\n",
    "meshNode= MeshNode(subject=101_0367,path=meshPath,getResource=True)\n",
    "\n",
    "#serialize nodes\n",
    "folder=os.path.join(projectPath ,'myAnalysisFolder','Meshes')\n",
    "if not os.path.exists(folder):\n",
    "    os.mkdir(folder)\n",
    "graphPath=os.path.join(projectPath ,'myAnalysisFolder','Meshes','meshGraph101_0367.ttl')\n",
    "meshNode.to_graph(graphPath=graphPath,save=True)\n",
    "{key:value for key, value in meshNode.__dict__.items() if not key.startswith('__') and not callable(key)}     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SessionNode\n",
    "From the above nodes, a overarching session can be created. As such, 2 sessions are created, one for each meaurement epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "file:///101_0367\n"
     ]
    }
   ],
   "source": [
    "linkedNodes=pcdNodes + imageNode + [meshNode]\n",
    "sess101_0367=SessionNode(subject='101_0367', linkedNodes=linkedNodes)\n",
    "print(len(sess101_0367.linkedNodes))\n",
    "print(sess101_0367.subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess101_0367.save_resource(os.path.join(projectPath ,'myAnalysisFolder'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fig.4**: (red) orientedBoundingBoxes of the pcdNodes and the meshNode, (red cones) scaled img field-of-views and (green) convex hull of the sessionNode.\n",
    "![rendering](../../pics/Session101_0367.JPG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcdboxes=[n.get_oriented_bounding_box() for n in pcdNodes ]\n",
    "for box in pcdboxes:\n",
    "    box.color=[1,0,0]\n",
    "# print(len(pcdboxes))\n",
    "\n",
    "imggeometries=[n.get_mesh_geometry(depth=2) for n in imageNode ]\n",
    "[img.paint_uniform_color([1,0,0]) for img in imggeometries]\n",
    "# print(len(imggeometries))\n",
    "\n",
    "meshbox=meshNode.get_oriented_bounding_box()\n",
    "meshbox.color=[1,0,0]\n",
    "# print(len([meshbox]))\n",
    "\n",
    "lineset1=o3d.geometry.LineSet.create_from_triangle_mesh(sess101_0366.resource)\n",
    "lineset1.paint_uniform_color([0,1,0])\n",
    "# print(len([lineset1]))\n",
    "\n",
    "\n",
    "mesh=o3d.io.read_triangle_mesh(meshPath)\n",
    "mesh.paint_uniform_color([1, 0.706, 0])\n",
    "mesh.compute_vertex_normals()\n",
    "\n",
    "\n",
    "o3d.visualization.draw_geometries( imggeometries + [meshbox] + [lineset1] + [mesh] + bimgeometries) #,lineset1,meshbox,imggeometries\n",
    "\n",
    "\n",
    "# print(len(geometries))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is good practice to already serialize these nodes in a RDF graph so we can rapidly load the nodes from the graphs in a next run. The facilitate the datastructure, we will store the generated graph in the same location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@prefix e57: <http://libe57.org#> .\n",
      "@prefix openlabel: <https://www.asam.net/index.php?eID=dumpFile&t=f&f=3876&token=413e8c85031ae64cc35cf42d0768627514868b2f#> .\n",
      "@prefix v4d: <https://w3id.org/v4d/core#> .\n",
      "\n",
      "<file:///101_0367> a v4d:SessionNode ;\n",
      "    e57:cartesianBounds \"\"\"[1.00536941e+05 1.00650704e+05 1.96207552e+05 1.96336026e+05\n",
      " 4.66497074e+00 3.87876819e+01]\"\"\" ;\n",
      "    e57:cartesianTransform \"\"\"[[1.00000000e+00 0.00000000e+00 0.00000000e+00 1.00591584e+05]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 1.96265479e+05]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00 2.60218133e+01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00]]\"\"\" ;\n",
      "    v4d:linkedSubjects \"['file:///PCDLAMBERT72_TAW', 'file:///101_0367_0001', 'file:///101_0367_0002', 'file:///101_0367_0003', 'file:///101_0367_0004', 'file:///101_0367_0005', 'file:///101_0367_0006', 'file:///101_0367_0007', 'file:///101_0367_0008', 'file:///101_0367_0009', 'file:///101_0367_0010', 'file:///101_0367_0011', 'file:///101_0367_0012', 'file:///101_0367_0013', 'file:///101_0367_0014', 'file:///101_0367_0015', 'file:///101_0367_0016', 'file:///101_0367_0017', 'file:///101_0367_0018', 'file:///101_0367_0019', 'file:///101_0367_0020', 'file:///101_0367_0021', 'file:///101_0367_0022', 'file:///101_0367_0023', 'file:///101_0367_0024', 'file:///101_0367_0025', 'file:///101_0367_0026', 'file:///101_0367_0027', 'file:///101_0367_0028', 'file:///101_0367_0029', 'file:///101_0367_0030', 'file:///101_0367_0031', 'file:///101_0367_0032', 'file:///101_0367_0033', 'file:///101_0367_0034', 'file:///101_0367_0035', 'file:///101_0367_0036', 'file:///101_0367_0037', 'file:///101_0367_0038', 'file:///101_0367_0039', 'file:///101_0367_0040', 'file:///101_0367_0041', 'file:///101_0367_0042', 'file:///101_0367_0043', 'file:///101_0367_0044', 'file:///101_0367_0045', 'file:///101_0367_0046', 'file:///101_0367_0047', 'file:///101_0367_0048', 'file:///101_0367_0049', 'file:///101_0367_0050', 'file:///101_0367_0051', 'file:///101_0367_0052', 'file:///101_0367_0053', 'file:///101_0367_0054', 'file:///101_0367_0055', 'file:///101_0367_0056', 'file:///101_0367_0057', 'file:///101_0367_0058', 'file:///101_0367_0059', 'file:///101_0367_0060', 'file:///101_0367_0061', 'file:///101_0367_0062', 'file:///101_0367_0063', 'file:///101_0367_0064', 'file:///101_0367_0065', 'file:///101_0367_0066', 'file:///101_0367_0067', 'file:///101_0367_0068', 'file:///101_0367_0069', 'file:///101_0367_0070', 'file:///101_0367_0071', 'file:///101_0367_0072', 'file:///101_0367_0073', 'file:///101_0367_0074', 'file:///101_0367_0075', 'file:///101_0367_0076', 'file:///101_0367_0077', 'file:///101_0367_0078', 'file:///1010367']\" ;\n",
      "    v4d:name \"101_0367\" ;\n",
      "    v4d:orientedBounds \"\"\"[[ 1.00634191e+05  1.96360505e+05  3.39444727e+01]\n",
      " [ 1.00688201e+05  1.96237195e+05  3.58175669e+01]\n",
      " [ 1.00515284e+05  1.96308505e+05  3.92783745e+01]\n",
      " [ 1.00633045e+05  1.96359459e+05 -1.80670225e+00]\n",
      " [ 1.00568147e+05  1.96184149e+05  5.40029379e+00]\n",
      " [ 1.00514137e+05  1.96307459e+05  3.52719954e+00]\n",
      " [ 1.00687054e+05  1.96236149e+05  6.63919985e-02]\n",
      " [ 1.00569293e+05  1.96185194e+05  4.11514687e+01]]\"\"\" ;\n",
      "    v4d:path \"101_0367.ply\" ;\n",
      "    openlabel:timestamp \"2022-07-19T16:21:08\" .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "graphPath=os.path.join(projectPath ,'myAnalysisFolder','sessionGraph101_0367.ttl')\n",
    "sess101_0367.to_graph(graphPath=graphPath,save=True)\n",
    "print(sess101_0367.graph.serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reloading from graph\n",
    "Similar to the BIM preprocessing, the above steps only have to be performed once. On reruns of the code or future analysis, we can initialize the same nodes from their serialized triples. This is significantly faster for smaller graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    }
   ],
   "source": [
    "sessionGraphPath=os.path.join(projectPath ,'myAnalysisFolder','sessionGraph101_0367.ttl')\n",
    "week22=SessionNode(graphPath=sessionGraphPath)\n",
    "\n",
    "#get resourceGraphs\n",
    "resourceGraph=Graph().parse(os.path.join(projectPath,'myAnalysisFolder','Photos','imageGraph101_0367.ttl') )\n",
    "resourceGraph+=Graph().parse(os.path.join(projectPath ,'myAnalysisFolder','Meshes','meshGraph101_0367.ttl'))\n",
    "resourceGraph+=Graph().parse(os.path.join(projectPath,'myAnalysisFolder','PCD','pcdGraph101_0367.ttl'))\n",
    "\n",
    "sess101_0367.get_linked_nodes(resourceGraph=resourceGraph)\n",
    "print(len(linkedNodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Volume calculation between two epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the both meshes one in yellow and one in grey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh1=[n.resource for n in sess101_0366.linkedNodes if 'TriangleMesh' in str(type(n.resource))]\n",
    "mesh1=mesh1[0]\n",
    "# print(mesh1)\n",
    "mesh1.compute_vertex_normals()\n",
    "mesh2=[n.resource for n in sess101_0367.linkedNodes if 'TriangleMesh' in str(type(n.resource))]\n",
    "mesh2=mesh2[0]\n",
    "mesh2.compute_vertex_normals()\n",
    "mesh2.paint_uniform_color([1, 0.706, 0])\n",
    "\n",
    "o3d.visualization.draw_geometries([mesh1] + [mesh2] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two grids of rays are created one above and one beneath the meshes and bim, the height difference can be changed. Here the boundingbox of mesh 1, mesh of session 101_0366 is used to create a grid. The resolution, so distances between each point of the gris is 0.1m. The offset where the grid max is situated above the top of the bounding box and the grid max is siuated beneath the bottom of the bounding box is here 10m. The diection is the orientation of the grid rays where down is faced down and up is faced up.\n",
    "\n",
    "The bottom grid is only needed for the second method, calculation of volumes between bim and mesh.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution=0.1 #m\n",
    "\n",
    "gridFlightMax=gmu.create_xy_grid(mesh1,resolution=resolution,direction='Down',offset=10) #offset in m\n",
    "gridFlightMin=gmu.create_xy_grid(mesh1,resolution=resolution,direction='Up',offset=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grids of these rays are transformed in to grids of points to visualize these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "xyzFlightMax=gridFlightMax[:,0:3]  \n",
    "pcdFlightMax = o3d.geometry.PointCloud()\n",
    "pcdFlightMax.points = o3d.utility.Vector3dVector(xyzFlightMax.numpy())\n",
    "\n",
    "xyzFlightMin=gridFlightMin[:,0:3]  \n",
    "pcdFlightMin = o3d.geometry.PointCloud()\n",
    "pcdFlightMin.points = o3d.utility.Vector3dVector(xyzFlightMin.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fig.5**: Creation of the grids with the both meshes for the calculation between two epochs. \n",
    "![rendering](../../pics/Creation_grids.PNG) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mesh=o3d.io.read_triangle_mesh(meshPath)\n",
    "# mesh.compute_vertex_normals()\n",
    "o3d.visualization.draw_geometries([mesh1] + [pcdFlightMax] + [pcdFlightMin] + [mesh2] + bimgeometries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the volume change between the two epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create depthmaps of the gridMax with both meshes, where every point has a value with the distance of the point to the mesh. If the ray doesn't intersect with the mesh the value is \"-Inf\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "depthmapF1=gmu.get_mesh_intersections(mesh1,gridFlightMax)\n",
    "depthmapF2=gmu.get_mesh_intersections(mesh2,gridFlightMax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the difference between both depthmaps, this gives a value with the distancee between the two meshes where a positive value is where mesh 1, session 101_0366, is beneath mesh 2, session 101_0367."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\beheerder\\AppData\\Local\\Temp\\ipykernel_10188\\3747729355.py:1: RuntimeWarning: invalid value encountered in subtract\n",
      "  depthmapDifference = np.asarray(depthmapF1-depthmapF2)\n"
     ]
    }
   ],
   "source": [
    "depthmapDifference = np.asarray(depthmapF1-depthmapF2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete the depthmap at the edges because of a bad photogrammetric reconstruction, you can change the distance to the edges in the function, default 1m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "depthmapDifference=gmu.remove_edges_volume_calculation(depthmapDifference,distance=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fig.6**: Coloured pointcloud where everything that is coloured green is a fill and everything that is coloured red is cut, the grey points are a buffer where the volume changes are within the 3cm. \n",
    "![rendering](../../pics/removed_edges.PNG) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fig.7**: Coloured pointcloud where the edges are still visible which gives dark colors. \n",
    "![rendering](../../pics/Colored_pointcloud_two_epochs.JPG) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Colour the pointcloud gradually everything that is coloured green is a fill and everything that is coloured red is a cut, the grey points are a buffer where the volume changes are within the 3cm, this value can be changed in the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointCloud with 901688 points.\n"
     ]
    }
   ],
   "source": [
    "coloredpcd=gmu.color_pointcloud_by_height(pcdFlightMax, depthmapDifference, buckets= 5, hmax = 5, buffer=0.03)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise the coloured pointcloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries( [coloredpcd])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a volume depthmap : the difference depthmap multiplied with the resolution squared, this gives a differnce volume per point of the grid. Where a positive value is a fill and a negative value is a cut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "volumeDepthmap=depthmapDifference*resolution*resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the volumeDepthmap in fill and cut additionally they can be substracted to give a overall view of the volume calculation (there is a limit of 100m because when there is no intersection the algorithm gives inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill=0\n",
    "cut=0\n",
    "\n",
    "for x in volumeDepthmap:\n",
    "    if x>0 and x<100:\n",
    "        fill=fill + x\n",
    "    elif x<0 and x > -100:\n",
    "        cut= cut + x\n",
    "\n",
    "totalVolume=fill+cut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The paths are changed to strings in order to print the volumechanges to create a numeric output too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "meshPath = os.path.join(projectPath ,'Meshes','101_0366','MeshLAMBERT72_TAW.ply')\n",
    "mesh2Path = os.path.join(projectPath ,'Meshes','101_0367','MeshLAMBERT72_TAW.ply')\n",
    "\n",
    "string1=str(meshPath)\n",
    "string2=str(mesh2Path)\n",
    "\n",
    "flightname1=string1.split('\\\\')\n",
    "flightname1=flightname1[-2]\n",
    "flightname2=string2.split('\\\\')\n",
    "flightname2=flightname2[-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cut fill and total volume are printed with the two epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The soil that is filled in this project between flight 101_0366 and 101_0367 is 294.87 m\n",
      "The soil that is cut in this project between flight 101_0366 and 101_0367 is -35.3 m\n",
      "The absolute volume change between flight 101_0366 and 101_0367 is 259.57 m.\n"
     ]
    }
   ],
   "source": [
    "print(\"The soil that is filled in this project between flight \" + flightname1 + \" and \" +  flightname2 + \" is \" + str(round(fill,2)) + \" m\")\n",
    "print(\"The soil that is cut in this project between flight \" + flightname1 + \" and \" +  flightname2 + \" is \" + str(round(cut,2)) + \" m\") #str(round(cut[0],2)) when not zero\n",
    "print(\"The absolute volume change between flight \" + flightname1 + \" and \" +  flightname2 + \" is \"  + str(round(totalVolume,2)) + \" m.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save a textfile in the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(os.path.join(projectPath ,'myAnalysisFolder','Mesh_vs_mesh.txt'),\"w+\")\n",
    "l1 = str(\"The soil that is filled in this project between flight \" + flightname1 + \" and \" +  flightname2 + \" is \" + str(round(fill,2)) + \" m. \\n\")\n",
    "l2 = str(\"The soil that is cut in this project between flight \" + flightname1 + \" and \" +  flightname2 + \" is \" + str(round(cut,2)) + \" m. \\n\")\n",
    "l3 = str(\"The absolute volume change between flight \" + flightname1 + \" and \" +  flightname2 + \" is \"  + str(round(totalVolume,2)) + \" m. \\n\")\n",
    "l=[l1 , l2, l3]\n",
    "file.writelines(l)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export the pointcloud in the folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointcloudPath=os.path.join(projectPath ,r\"myAnalysisFolder\\colouredPCD.pcd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o3d.io.write_point_cloud(pointcloudPath, coloredpcd, write_ascii=False, compressed=False, print_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the volume change between the an epoch and the as-design bim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the grid per object of the bim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign distances to parameters to expand the bounding boxes of the bim elements to crop the grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "u=0# (float) search distance in X given the boundingbox\n",
    "v=0 # (float) search distance in Y given the boundingbox\n",
    "z=40 # (float) search distance in Z given the boundingbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in bimNodes:\n",
    "    if getattr(node,'orientedBounds',None) is not None:\n",
    "        bb=node.resource.get_axis_aligned_bounding_box()\n",
    "        a=bb.get_oriented_bounding_box()\n",
    "        node.box=a   \n",
    "        node.box=gmu.expand_box(node.box,u=u,v=v,w=z)\n",
    "        node.box.color=[0,1,0]   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crop the grids per bim object to grid max and a grid min using the expanded bounding boxes of the bim elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "bimboxes=[node.box for node in bimNodes if node.box != None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bimnode in bimNodes:\n",
    "    bimnode.croppedPcdMax=o3d.geometry.PointCloud()\n",
    "    bimnode.croppedPcdMax=gmu.crop_geometry_by_box(pcdFlightMax, bimnode.box )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bimnode in bimNodes:\n",
    "    bimnode.croppedPcdMin=o3d.geometry.PointCloud()\n",
    "    bimnode.croppedPcdMin=gmu.crop_geometry_by_box(pcdFlightMin, bimnode.box )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "color the min grid red and the plus grid blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcdFlightMax.paint_uniform_color([0,0,1])\n",
    "pcdFlightMin.paint_uniform_color([1,0,0])\n",
    "boxes=[node.box for node in bimNodes if node.box != None]\n",
    "croppedPcdsMax=[node.croppedPcdMax for node in bimNodes if node.croppedPcdMax != None]\n",
    "croppedPcdsMin=[node.croppedPcdMin for node in bimNodes if node.croppedPcdMin != None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a grid of rays using the grid of points per element that was just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "bimgeometries=[n.resource for n in bimNodes if n.resource]\n",
    "raysDown=gmu.get_rays_raycast(bimNodes,\"Down\")\n",
    "raysUp=gmu.get_rays_raycast(bimNodes,\"up\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the created grid of rays to create two depthmaps of the bim elements, a plus grid and a min grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "depthmapBimMax=gmu.get_bim_intersections(bimgeometries,raysDown)\n",
    "depthmapBimMinTemp=gmu.get_bim_intersections(bimgeometries,raysUp)\n",
    "griddifference=xyzFlightMax[0,2]-xyzFlightMin[0,2] #calculate the difference in z, is the same for every point of the gris\n",
    "depthmapBimMin = [griddifference - x for x in depthmapBimMinTemp]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fig.8**: Creation of the grids with the both meshes for the calculation between an epoch and the bim. \n",
    "![rendering](../../pics/Calculation_volume_mesh_vs_BIM_grid.PNG) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries(  [mesh2]+ bimgeometries +[pcdFlightMin]+ [pcdFlightMax]  ) #+[pcdFlightMin]+ [pcdFlightMax] + boxes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a depthmap of the flight but in this case one per object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "depthmapFBIM=pt.get_mesh_intersectionsBIM(mesh,raysDown)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate the volume between the mesh and the bim\n",
    "$$ d(x,y)=\n",
    "\\begin{cases}\n",
    "\\  0 & ,  d_{f}\\geq (d_{b,max}-d_{b,min}) \\\\\n",
    "\\  (d_{b,max}-d_{b,min}) & ,  d_{f}\\leq d_{b,max} \\\\\n",
    "\\  (d_{f}-d_{b,min}) &,  else\\\\\n",
    "\\end{cases} $$\n",
    "\n",
    "$$ \\begin{split}\n",
    "% flight vs BIM\n",
    "& V= \\iint_{X_{b_n},Y_{b_n}}^{} \\delta r^2 d(x,y) \\,dx\\,dy\n",
    "\\end{split} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "volumeMeshBIM=pt.volume_mesh_BIM(depthmapFBIM,depthmapBimMin,depthmapBimMax,resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the theoretical volume of the bim itself, when the objects are not watertight this function will still work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "volumeBIM=pt.volume_theoretical_BIM(depthmapBimMin,depthmapBimMax,resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(volumeBIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the completion per element, by deviding the volume by the theoretical volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion=pt.calculate_completion(volumeMeshBIM,volumeBIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Color the bim model by comlpletion. 95% completion or more is green, between 50% and 95% it's coloured yellow, between 25% and 50% its coloured orange and less than 25% its coloured red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt.color_BIMNode(completion, bimNodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise the bim model with the colours of the completion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "geometries=[a.resource for a in bimNodes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fig.9**: Colored ifc model by the completion of each model. \n",
    "![rendering](../../pics/Colered_bim_by_completion.PNG) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries(geometries) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the total completion and total volume of the mesh compared to the BIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalVolumeMeshBIM=0\n",
    "totalVolumeBIM=0\n",
    "\n",
    "for i,element in enumerate(volumeMeshBIM):\n",
    "    totalVolumeMeshBIM = totalVolumeMeshBIM + volumeMeshBIM[i]\n",
    "\n",
    "for i,element in enumerate(volumeBIM):\n",
    "    totalVolumeBIM = totalVolumeBIM + volumeBIM[i]\n",
    "\n",
    "totalCompletion=(totalVolumeMeshBIM/totalVolumeBIM)*100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print for each element the completion and the volume of that element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The completion of bim element (0) is 5.92 % with a volume of 1.76m\n",
      "The completion of bim element (1) is 1.69 % with a volume of 0.02m\n",
      "The completion of bim element (2) is 0.62 % with a volume of 0.01m\n",
      "The completion of bim element (3) is 2.19 % with a volume of 0.76m\n",
      "The completion of bim element (4) is 28.13 % with a volume of 6.03m\n",
      "The completion of bim element (5) is 0.01 % with a volume of 0.0m\n",
      "The completion of bim element (6) is 7.13 % with a volume of 0.72m\n",
      "The completion of bim element (7) is 81.09 % with a volume of 8.08m\n",
      "The completion of bim element (8) is 0.0 % with a volume of 0.0m\n",
      "The completion of bim element (9) is 6.36 % with a volume of 1.76m\n",
      "The completion of bim element (10) is 1.12 % with a volume of 0.12m\n",
      "The completion of bim element (11) is 0.0 % with a volume of 0.0m\n",
      "The completion of bim element (12) is 4.11 % with a volume of 1.14m\n",
      "The completion of bim element (13) is 64.4 % with a volume of 0.06m\n",
      "The completion of bim element (14) is 56.85 % with a volume of 0.07m\n",
      "The completion of bim element (15) is 62.62 % with a volume of 0.06m\n",
      "The completion of bim element (16) is 62.68 % with a volume of 0.08m\n",
      "The completion of bim element (17) is 47.77 % with a volume of 0.08m\n",
      "The completion of bim element (18) is 81.47 % with a volume of 31.19m\n",
      "The completion of bim element (19) is 64.61 % with a volume of 0.08m\n",
      "The completion of bim element (20) is 60.65 % with a volume of 0.07m\n",
      "The completion of bim element (21) is 46.77 % with a volume of 0.08m\n",
      "The completion of bim element (22) is 79.43 % with a volume of 26.02m\n",
      "The completion of bim element (23) is 100.0 % with a volume of 8.14m\n",
      "The completion of bim element (24) is 92.45 % with a volume of 0.96m\n",
      "The completion of bim element (25) is 7.76 % with a volume of 0.01m\n",
      "The completion of bim element (26) is 22.04 % with a volume of 0.03m\n",
      "The completion of bim element (27) is 16.17 % with a volume of 0.02m\n",
      "The completion of bim element (28) is 0.0 % with a volume of 0.0m\n",
      "The completion of bim element (29) is 0.0 % with a volume of 0.0m\n",
      "The completion of bim element (30) is 0.0 % with a volume of 0.0m\n",
      "The completion of bim element (31) is 29.1 % with a volume of 0.04m\n",
      "The completion of bim element (32) is 8.59 % with a volume of 0.0m\n",
      "The completion of bim element (33) is 2.28 % with a volume of 0.0m\n",
      "The completion of bim element (34) is 12.6 % with a volume of 0.02m\n",
      "The completion of bim element (35) is 0.0 % with a volume of 0.0m\n",
      "The completion of bim element (36) is 23.59 % with a volume of 0.03m\n",
      "The completion of bim element (37) is 49.08 % with a volume of 1.2m\n",
      "The completion of bim element (38) is 0.0 % with a volume of 0.0m\n",
      "The completion of bim element (39) is 0.0 % with a volume of 0.0m\n",
      "The completion of bim element (40) is 0.0 % with a volume of 0.0m\n",
      "The completion of bim element (41) is 0.0 % with a volume of 0.0m\n",
      "The completion of bim element (42) is 0.0 % with a volume of 0.0m\n",
      "The completion of bim element (43) is 0.0 % with a volume of 0.0m\n",
      "The completion of bim element (44) is 0.0 % with a volume of 0.0m\n",
      "The completion of bim element (45) is 0.0 % with a volume of 0.0m\n",
      "The completion of bim element (46) is 0.0 % with a volume of 0.0m\n",
      "The completion of bim element (47) is 0.0 % with a volume of 0.0m\n",
      "The completion of bim element (48) is 0.0 % with a volume of 0.0m\n",
      "The completion of bim element (49) is 19.37 % with a volume of 0.05m\n",
      "The completion of bim element (50) is 0.0 % with a volume of 0.0m\n",
      "The completion of bim element (51) is 0.0 % with a volume of 0.0m\n",
      "The completion of bim element (52) is 1.52 % with a volume of 0.0m\n",
      "The completion of bim element (53) is 2.31 % with a volume of 0.01m\n",
      "The completion of bim element (54) is 0.0 % with a volume of 0.0m\n",
      "The completion of bim element (55) is 0.0 % with a volume of 0.0m\n",
      "The completion of bim element (56) is 0.0 % with a volume of 0.0m\n",
      "The completion of bim element (57) is 0.0 % with a volume of 0.0m\n",
      "The completion of bim element (58) is 0.0 % with a volume of 0.0m\n",
      "The completion of bim element (59) is 0.0 % with a volume of 0.0m\n",
      "The completion of bim element (60) is 0.0 % with a volume of 0.0m\n",
      "The completion of bim element (61) is 38.34 % with a volume of 0.4m\n",
      "The completion of bim element (62) is 34.41 % with a volume of 0.25m\n",
      "The completion of bim element (63) is 98.41 % with a volume of 1.17m\n",
      "The total completion of the site is 24.28 % with a volume of 90.52m\n"
     ]
    }
   ],
   "source": [
    "for i,element in enumerate(volumeMeshBIM): \n",
    "    if completion[i] != None:\n",
    "        print(\"The completion of bim element (\" + str(i) +\") is \" + str(np.round((completion[i]*100),2)) + \" %\" + \" with a volume of \" + str(np.round(volumeMeshBIM[i],2)) + \"m\")\n",
    "    else:\n",
    "        print(\"The completion of bim element (\" + str(i) +\") is None\" + \" with a volume of \" + str(np.round(volumeMeshBIM[i],2)) + \"m\")\n",
    "\n",
    "print(\"The total completion of the site is \" + str(np.round((totalCompletion),2)) + \" % with a volume of \" + str(np.round(totalVolumeMeshBIM,2)) + \"m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[]\n",
    "li=''\n",
    "for i,element in enumerate(volumeMeshBIM): \n",
    "    li= str(\"The completion of bim element (\" + str(i) +\") is \" + str(np.round((completion[i]*100),2)) + \" %\" + \" with a volume of \" + str(np.round(volumeMeshBIM[i],2)) + \"m. \\n\")\n",
    "    l.append(li)\n",
    "\n",
    "t=str(\"The total completion of the site is \" + str(np.round((totalCompletion),2)) + \" % with a volume of \" + str(np.round(totalVolumeMeshBIM,2)) + \"m. \\n\")\n",
    "l.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(os.path.join(projectPath ,'myAnalysisFolder','Mesh_vs_BIM.txt'),\"w+\")\n",
    "file.writelines(l)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create  a new path to save the bim model one by one and a full model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "colouredMeshPath=os.path.join(projectPath ,r\"myAnalysisFolder\\couleredIFC\")\n",
    "if not os.path.exists(colouredMeshPath):\n",
    "    os.mkdir(colouredMeshPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save each bim object itself in colour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in bimNodes:\n",
    "    node.save_subjectresource(colouredMeshPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join the geometries and save them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "joinedGeometries=gmu.join_geometries(geometries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colouredMeshPath=os.path.join(projectPath ,r\"myAnalysisFolder\\couleredIFC\\colouredIFC.ply\")\n",
    "o3d.io.write_triangle_mesh(colouredMeshPath, joinedGeometries, write_ascii=False, compressed=False, write_vertex_normals=True, write_vertex_colors=True, write_triangle_uvs=True, print_progress=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('conda_environment3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "abad92001355afe429be1f0fa7545e029d4c02982ac04bdb99fefc78fd2f2328"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
