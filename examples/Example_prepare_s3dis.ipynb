{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPARE S3DIS to training data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "#IMPORT PACKAGES\n",
    "import os.path\n",
    "import importlib\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "import open3d as o3d\n",
    "import uuid    \n",
    "import pye57 \n",
    "import ifcopenshell\n",
    "import ifcopenshell.geom as geom\n",
    "import ifcopenshell.util\n",
    "from ifcopenshell.util.selector import Selector\n",
    "import random as rd\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import laspy\n",
    "import copy\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "import pathlib\n",
    "\n",
    "#IMPORT MODULES\n",
    "from context import geomapi \n",
    "from geomapi.nodes import *\n",
    "import geomapi.utils as ut\n",
    "from geomapi.utils import geometryutils as gmu\n",
    "from geomapi.utils import imageutils as iu\n",
    "import geomapi.tools as tl\n",
    "from geomapi.tools import progresstools as pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INPUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_in=\"D:/Data/Stanford3dDataset_v1.2_Aligned_Version/Stanford3dDataset_v1.2_Aligned_Version\"\n",
    "dir_out=\"D:/Data/Stanford3dDataset_v1.2_Aligned_Version/Prepared\"\n",
    "\n",
    "train_areas = ['Area_1', 'Area_2', 'Area_3', 'Area_4', 'Area_6']\n",
    "# test_areas = ['Area_5']\n",
    "# test_area=5\n",
    "# split='train' #'test'\n",
    "classes=['ceiling','floor','wall','column','beam','window','door','table','chair','bookcase','sofa','board','clutter','stairs']\n",
    "movePoints=True\n",
    "includeHeight=True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse S3DIS data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Area_1', 'Area_2', 'Area_3', 'Area_4', 'Area_5', 'Area_6']\n",
      "Area_5\n"
     ]
    }
   ],
   "source": [
    "# get areas\n",
    "area_list = sorted(os.listdir(dir_in))\n",
    "area_list = [item for item in area_list if 'Area_' in item]\n",
    "print(area_list)\n",
    "\n",
    "for area in area_list[4:5]: \n",
    "    print(area)\n",
    "    i=area[-1]\n",
    "    df_total=pd.DataFrame()\n",
    "    \n",
    "    #get rooms  \n",
    "    room_list = sorted([d for d in os.listdir(os.path.join(dir_in,area)) if os.path.isdir(os.path.join(os.path.join(dir_in,area), d))])\n",
    "    \n",
    "    for r,room in enumerate(room_list[0:5]): #! temp\n",
    "        #get points\n",
    "        dir=os.path.join(dir_in,area,room,'Annotations')                    \n",
    "        files=[f for f in ut.get_list_of_files(dir)  if f.endswith('.txt')]\n",
    "        for f in files:\n",
    "            #convert name to index\n",
    "            name=ut.get_filename(f,'_')\n",
    "            index=classes.index(name)\n",
    "            \n",
    "            #read points\n",
    "            df=pd.read_csv(f,sep=' ',names=['x','y','z','r','g','b']) \n",
    "            \n",
    "            #optionally displace points\n",
    "            if movePoints:\n",
    "                columns=r%10\n",
    "                rows=math.floor(r/10)\n",
    "                transform=gmu.get_cartesian_transform(translation=np.array([50*rows,50*columns,0]))\n",
    "                df=gmu.transform_dataframe(df,transform=transform)\n",
    "            \n",
    "            #add index as point field \n",
    "            df['label']=pd.DataFrame(np.full((df.shape[0],1),index))\n",
    "\n",
    "            #combine dataframes\n",
    "            df_total=pd.concat([df_total,df], ignore_index=False)\n",
    "    \n",
    "    # 1. Create a new header\n",
    "    header = laspy.LasHeader(point_format=3, version=\"1.2\")\n",
    "    header.add_extra_dim(laspy.ExtraBytesParams(name=\"R\", type=np.int32))\n",
    "    header.add_extra_dim(laspy.ExtraBytesParams(name=\"G\", type=np.int32))\n",
    "    header.add_extra_dim(laspy.ExtraBytesParams(name=\"B\", type=np.int32))\n",
    "    header.add_extra_dim(laspy.ExtraBytesParams(name=\"label\", type=np.int32))\n",
    "    header.add_extra_dim(laspy.ExtraBytesParams(name=\"height\", type=np.float32)) if includeHeight else None  \n",
    "    # header.offsets = np.min(df_total, axis=0)\n",
    "    # header.scales = np.array([0.1, 0.1, 0.1])\n",
    "\n",
    "    # 2. Create a Las\n",
    "    las = laspy.LasData(header)\n",
    "    las.x = df_total.iloc[:,0].to_numpy()\n",
    "    las.y = df_total.iloc[:,1].to_numpy()\n",
    "    las.z = df_total.iloc[:,2].to_numpy()\n",
    "    las.red = df_total.iloc[:,3].to_numpy()\n",
    "    las.green = df_total.iloc[:,4].to_numpy()\n",
    "    las.blue = df_total.iloc[:,5].to_numpy()\n",
    "    las.label =df_total.iloc[:,6].to_numpy()\n",
    "\n",
    "    #(optional height)\n",
    "    if includeHeight:   \n",
    "        las.height=las.z-np.min(las.z)\n",
    "    \n",
    "    #write las\n",
    "    las.write(os.path.join(dir_out,f'Area_{i}_labeled.las'))        \n",
    "            \n",
    "    # print(df_total.head)\n",
    "    print(df_total.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "export as las file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1. Create a new header\n",
    "# header = laspy.LasHeader(point_format=3, version=\"1.2\")\n",
    "# header.add_extra_dim(laspy.ExtraBytesParams(name=\"R\", type=np.int32))\n",
    "# header.add_extra_dim(laspy.ExtraBytesParams(name=\"G\", type=np.int32))\n",
    "# header.add_extra_dim(laspy.ExtraBytesParams(name=\"B\", type=np.int32))\n",
    "# header.add_extra_dim(laspy.ExtraBytesParams(name=\"label\", type=np.int32))\n",
    "\n",
    "# # header.offsets = np.min(df_total, axis=0)\n",
    "# # header.scales = np.array([0.1, 0.1, 0.1])\n",
    "\n",
    "# # 2. Create a Las\n",
    "# las = laspy.LasData(header)\n",
    "# las.x = df_total.iloc[:,0].to_numpy()\n",
    "# las.y = df_total.iloc[:,1].to_numpy()\n",
    "# las.z = df_total.iloc[:,2].to_numpy()\n",
    "# las.red = df_total.iloc[:,3].to_numpy()\n",
    "# las.green = df_total.iloc[:,4].to_numpy()\n",
    "# las.blue = df_total.iloc[:,5].to_numpy()\n",
    "# las.label =df_total.iloc[:,6].to_numpy()\n",
    "\n",
    "# #(optional height)\n",
    "# if includeHeight:   \n",
    "#     las.header.add_extra_dim(laspy.ExtraBytesParams(name=\"height\", type=np.int32))\n",
    "#     las.height=las.z-np.min(las.z)\n",
    "\n",
    "# #write las\n",
    "# las.write(os.path.join(dir_out,f'Area_{5}_labeled.las'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optional, export dataframes with labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export DataFrame to text file\n",
    "with open(os.path.join(dir_out,f'Area_{5}_labeled.txt'), 'a') as f:\n",
    "    df_string = df_total.to_string(header=False, index=False)\n",
    "    f.write(df_string)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optionally, convert to pcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointCloud with 5836948 points.\n"
     ]
    }
   ],
   "source": [
    "pcd=gmu.dataframe_to_pcd(df_total,xyz=[0,1,2],rgb=[3,4,5])\n",
    "print(pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optionally, color by class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get classes\n",
    "classArray=df_total.iloc[:,6].to_numpy() \n",
    "colors=gmu.array_to_colors(classArray)\n",
    "pcd.colors=o3d.utility.Vector3dVector(colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: De aangevraagde overdrachtsbewerking wordt niet ondersteund. \n"
     ]
    }
   ],
   "source": [
    "o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classes=['ceiling','floor','wall','column','beam','window','door','table','chair','bookcase','sofa','board','clutter','stairs']\n",
    "normals\n",
    "planarity 0.2 -> floors, ceilings, walls\n",
    "verticallity 0.05\n",
    "surface variation 0.10\n",
    "sum eigenvalues 0.1 -> goed voor deurlijsten\n",
    "omnivariance 0.05 -> goed voor clutter, deuren\n",
    "eigenentropy 0.02 -> good voor clutter\n",
    "eigenvalue 0.1 -> medium clutter\n",
    "roughness\n",
    "'column','beam'\n",
    "beams -> density in Z\n",
    "sphericity -> half a meter?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "not:\n",
    "same as eigenvalues\n",
    "surface variation 0.05 -> respons well for clutter (leggs of chairs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_environment3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
