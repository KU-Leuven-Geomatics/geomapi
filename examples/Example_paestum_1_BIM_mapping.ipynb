{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAP BIM INFORMATION TO A LAS POINT CLOUD\n",
    "In this notebook, we select specific elements and classes from an IFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "#IMPORT PACKAGES\n",
    "from rdflib import Graph, URIRef\n",
    "import os.path\n",
    "import importlib\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "import open3d as o3d\n",
    "import uuid    \n",
    "import pye57 \n",
    "import ifcopenshell\n",
    "import ifcopenshell.geom as geom\n",
    "import ifcopenshell.util\n",
    "from ifcopenshell.util.selector import Selector\n",
    "import multiprocessing\n",
    "import random as rd\n",
    "import pandas as pd\n",
    "# from tabulate import tabulate\n",
    "import cv2\n",
    "\n",
    "#IMPORT MODULES\n",
    "from context import geomapi \n",
    "from geomapi.nodes import *\n",
    "import geomapi.utils as ut\n",
    "from geomapi.utils import geometryutils as gmu\n",
    "import geomapi.tools as tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USER INPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS\n",
    "projectPath= os.path.join(\"D:\\\\Data\\\\2023-01 Paestum\")\n",
    "# sessionPath = os.path.join(projectPath,\"Research\")\n",
    "#BIM\n",
    "bimPath=os.path.join(projectPath,\"BIM\")\n",
    "ifcPath=os.path.join(projectPath,'BIM','Paestum.ifc')\n",
    "\n",
    "# bimClasses= {'COLONNA':['COLONNA','PARASTA'],\n",
    "#             'PILASTRO':'PILASTRO',\n",
    "#             'TRABEAZIONE':'TRABEAZIONE',\n",
    "#             'ARCO':'ARCO',\n",
    "#             'AGGETTO':'aggetto',\n",
    "#             'FACADE':['CORNICE','MUR']}\n",
    "\n",
    "transform=np.array([[1.0,0.0, 0.0,  5.3857862609899980e+000], \n",
    "                [0.0, 1.0, 0.0, 2.5782303777102851e+002],\n",
    "                [0.0, 0.0, 1.0 ,-6.0074548600459288e+000],\n",
    "                [0.0 ,0.0, 0.0, 1.000000000000]]) # -> apply to pcd\n",
    "    \n",
    "#PCD\n",
    "resolution=0.05\n",
    "distanceThreshold=0.2 #distance theshold for inliers\n",
    "lasPath=os.path.join(projectPath,'PCD','TEMPIO_all_predicted - Cloud.las')\n",
    "outputlasPath=os.path.join(projectPath,'PCD','TEMPIO_groundtruth1.las')\n",
    "\n",
    "#MESH\n",
    "meshFolderPath=os.path.join(projectPath,'MESH')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARSE INPUTS & CREATE NODES"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fig.**: Images of the BIM section of the colosseum with (a) BIM elements and (b) the point cloud, (c) selected subgroups per model type and (d) segmented point cloud per subgroup.\n",
    "\n",
    "<img src=\"../docs/pics/colosseum/columns1.PNG\" width = \"20%\">\n",
    "<img src=\"../docs/pics/colosseum/columns2.PNG\" width = \"25%\">\n",
    "\n",
    "<img src=\"../docs/pics/colosseum/columns3.PNG\" width = \"23%\">\n",
    "<img src=\"../docs/pics/colosseum/columns4.PNG\" width = \"20%\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.Import the IFC Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 214 BIMNodes created!\n"
     ]
    }
   ],
   "source": [
    "bimNodes=tl.ifc_to_nodes_multiprocessing(ifcPath,offsetTransform=transform)\n",
    "# for n in bimNodes:\n",
    "    # n.cartesianTransform= transform \n",
    "    # n.resource.transform(transform)\n",
    "bimNodes=[n for n in bimNodes if n.resource is not None]\n",
    "print(f' {str(len(bimNodes))} BIMNodes created!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_ifcPath': 'D:\\\\Data\\\\2023-01 Paestum\\\\BIM\\\\Paestum.ifc',\n",
       " '_globalId': '2m5cC6lu9D_9s0K5cLgC0n',\n",
       " '_cartesianBounds': array([-10.23262847,  -8.64633704,  -2.47863672,  -0.89234528,\n",
       "          1.45      ,   6.65      ]),\n",
       " '_orientedBounds': array([[ -8.77068506,  -2.59766762,   1.45      ],\n",
       "        [ -8.77068506,  -2.59766762,   6.65      ],\n",
       "        [ -8.52730613,  -1.01669331,   1.45      ],\n",
       "        [-10.35165937,  -2.35428869,   1.45      ],\n",
       "        [-10.10828044,  -0.77331438,   6.65      ],\n",
       "        [-10.10828044,  -0.77331438,   1.45      ],\n",
       "        [-10.35165937,  -2.35428869,   6.65      ],\n",
       "        [ -8.52730613,  -1.01669331,   6.65      ]]),\n",
       " '_orientedBoundingBox': OrientedBoundingBox: center: (-9.43948, -1.68549, 4.05), extent: 5.2, 1.5996, 1.5996),\n",
       " '_subject': rdflib.term.URIRef('file:///Colonna_Centrale_Colonna_Dorica_Centrale_142123_2m5cC6lu9D_9s0K5cLgC0n'),\n",
       " '_graph': None,\n",
       " '_graphPath': None,\n",
       " '_path': None,\n",
       " '_name': 'Colonna_Centrale:Colonna_Dorica_Centrale:142123',\n",
       " '_timestamp': '2023-02-01T08:36:38',\n",
       " '_resource': TriangleMesh with 2424 points and 4844 triangles.,\n",
       " '_cartesianTransform': array([[  1.        ,   0.        ,   0.        ,   5.38578626],\n",
       "        [  0.        ,   1.        ,   0.        , 257.82303777],\n",
       "        [  0.        ,   0.        ,   1.        ,  -6.00745486],\n",
       "        [  0.        ,   0.        ,   0.        ,   1.        ]]),\n",
       " 'offsetTransform': array([[  1.        ,   0.        ,   0.        ,   5.38578626],\n",
       "        [  0.        ,   1.        ,   0.        , 257.82303777],\n",
       "        [  0.        ,   0.        ,   1.        ,  -6.00745486],\n",
       "        [  0.        ,   0.        ,   0.        ,   1.        ]]),\n",
       " 'className': 'IfcColumn',\n",
       " 'pointCount': 2424,\n",
       " 'faceCount': 4844,\n",
       " 'objectType': 'Colonna_Centrale:Colonna_Dorica_Centrale'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{key:value for key, value in bimNodes[2].__dict__.items() if not key.startswith('__') and not callable(key)}              "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Select BIM objects per class based on their name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ABACO', 'Colonna_Grande_Centrale:Colonna_Dorica_Grande_Centrale', 'Pilastro_Piccolo:Pilastro_Piccolo', 'TIMPANO', 'Colonna_Centrale:Colonna_Dorica_Centrale', 'Colonna_Superiore_Centrale:Colonna_Dorica_Superiore_Centrale', 'Pilastro_Grande:Pilastro_Grande', 'ECHINO', 'ARCHITRAVE', 'Opening', 'CORNICE', 'Colonna_Esterna:colonna_dorica_esterna', 'Crepidoma:Crepidoma', 'FREGIO', 'Crepidoma_Centrale:Crepidoma_Centrale']\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "classes=[n.objectType for n in bimNodes]\n",
    "class_set=set(classes)\n",
    "unique_classes = (list(class_set))\n",
    "print (unique_classes)\n",
    "print (len(unique_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined=gmu.join_geometries([n.resource for n in bimNodes])\n",
    "o3d.io.write_triangle_mesh(os.path.join(meshFolderPath,f'bimMeshes.obj'),joined) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no Opening\n",
    "[garden, Crepidoma, top of Crepidoma, Colonna+Pilastro (maybe seperate these), ECHINO, ABACO,ARCHITRAVE,FREGIO,CORNICE,TIMPANO]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merge pilastro classes, colonna classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values([['COLONNA', 'PARASTA'], 'PILASTRO', 'TRABEAZIONE', 'ARCO', 'aggetto', ['CORNICE', 'MUR']])\n"
     ]
    }
   ],
   "source": [
    "print(bimClasses.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,  65, ['COLONNA', 'PARASTA'] !\n",
      "1,  75, ['PILASTRO'] !\n",
      "2,  13, ['TRABEAZIONE'] !\n",
      "3,  61, ['ARCO'] !\n",
      "4,  19, ['aggetto'] !\n",
      "5,  137, ['CORNICE', 'MUR'] !\n"
     ]
    }
   ],
   "source": [
    "# make this exclusive\n",
    "tcnodeLists=[]\n",
    "tcgeometries=[] \n",
    "for i,c,name in zip(range(len(bimClasses.values())),bimClasses.values(),bimClassNames):\n",
    "    #select nodes\n",
    "    c=ut.item_to_list(c)\n",
    "    tcnodeLists.append([n for n in bimNodes if any(name in n.name for name in c )])\n",
    "    print(f'{i},  {len(tcnodeLists[i])}, {c} !')\n",
    "    #combine geometries\n",
    "    if tcnodeLists[i] is not None:\n",
    "        tcgeometries.append(gmu.join_geometries([n.resource for n in tcnodeLists[i]]))\n",
    "        #export geometries     \n",
    "        o3d.io.write_triangle_mesh(os.path.join(MeshTCFolder,f'{i}_{ut.validate_string(name)}.obj'),tcgeometries[i]) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create point cloud per mesh geometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref_clouds= [gmu.mesh_sample_points_uniformly(mesh, resolution=0.1) for mesh in tcgeometries]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(optional) read sample mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mesh=o3d.io.read_triangle_mesh(meshPath)\n",
    "# k = round(mesh.get_surface_area() * 1000)\n",
    "# ref_clouds = [mesh.sample_points_uniformly(number_of_points = k, use_triangle_normal=True)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Create list of unique materials in the BIMNodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Calcestruzzo, gettato in opera', '<Unnamed>', 'CL_00_Calcestruzzo-Generico', 'PT_00_Pietra-Generico', 'PT_10_Pietra_Muratura-XXX-XXX-Secco_Pietrame', 'LT_00_Laterizio-Generico', 'PT_01_Pietra-Travertino', 'BT_00_Bitume-Generico', 'PT_23_Pietra_Rivestimento-XXX-XXX-PietraNaturale_Travertino', 'Sombra escala']\n"
     ]
    }
   ],
   "source": [
    "materials=[m for n in bimNodes for m in n.materials]\n",
    "materials_set=set(materials)\n",
    "unique_materials = (list(materials_set))\n",
    "print (unique_materials)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(optionally) save groups of materials as .obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,  13, Calcestruzzo, gettato in opera !\n",
      "1,  241, <Unnamed> !\n",
      "2,  15, CL_00_Calcestruzzo-Generico !\n",
      "3,  11, PT_00_Pietra-Generico !\n",
      "4,  6, PT_10_Pietra_Muratura-XXX-XXX-Secco_Pietrame !\n",
      "5,  45, LT_00_Laterizio-Generico !\n",
      "6,  4, PT_01_Pietra-Travertino !\n",
      "7,  2, BT_00_Bitume-Generico !\n",
      "8,  2, PT_23_Pietra_Rivestimento-XXX-XXX-PietraNaturale_Travertino !\n",
      "9,  8, Sombra escala !\n"
     ]
    }
   ],
   "source": [
    "# make this exclusive\n",
    "materialNodeLists=[]\n",
    "materialGeometries=[]\n",
    "for i,mat in enumerate(unique_materials):\n",
    "    #select nodes\n",
    "    materialNodeLists.append([n for n in bimNodes if any(m in mat for m in n.materials )])\n",
    "    print(f'{i},  {len(materialNodeLists[i])}, {mat} !')\n",
    "    # combine geometries\n",
    "    if materialNodeLists[i] is not None:\n",
    "        materialGeometries.append(gmu.join_geometries([n.resource for n in materialNodeLists[i]]))\n",
    "        #export geometries     \n",
    "        o3d.io.write_triangle_mesh(os.path.join(MeshMatFolder,f'{i}_{ut.validate_string(mat)}.obj'),materialGeometries[i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Add class and material indices to bimNodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in bimNodes:\n",
    "    for i, c in enumerate(bimClasses.values()):\n",
    "        if any(name in n.name for name in c ):\n",
    "            n.bimClassField= i \n",
    "            break  \n",
    "        else  :\n",
    "            n.bimClassField=-1 \n",
    "        \n",
    "    for i, mat in enumerate(unique_materials):\n",
    "        if len(n.materials)>0 and n.materials[0] in mat:\n",
    "            n.materialField1= i  \n",
    "            break\n",
    "        else:\n",
    "            n.materialField1=-1\n",
    "    for i, mat in enumerate(unique_materials):\n",
    "        if len(n.materials)>1 and n.materials[1] in mat:\n",
    "            n.materialField2= i  \n",
    "            break\n",
    "        else:\n",
    "            n.materialField2=-1        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_ifcPath': 'D:\\\\Data\\\\2023-01 Paestum\\\\BIM\\\\Paestum.ifc',\n",
       " '_globalId': '2m5cC6lu9D_9s0K5cLgC0W',\n",
       " '_cartesianBounds': array([ 0.24627407,  1.83256551, -2.47863672, -0.89234528,  1.45      ,\n",
       "         6.65      ]),\n",
       " '_orientedBounds': array([[ 0.24627407, -0.89234528,  6.65      ],\n",
       "        [ 0.24627407, -0.89234528,  1.45      ],\n",
       "        [ 1.83256551, -0.89234528,  6.65      ],\n",
       "        [ 0.24627407, -2.47863672,  6.65      ],\n",
       "        [ 1.83256551, -2.47863672,  1.45      ],\n",
       "        [ 1.83256551, -2.47863672,  6.65      ],\n",
       "        [ 0.24627407, -2.47863672,  1.45      ],\n",
       "        [ 1.83256551, -0.89234528,  1.45      ]]),\n",
       " '_orientedBoundingBox': OrientedBoundingBox: center: (1.03942, -1.68549, 4.05), extent: 5.2, 1.58629, 1.58629),\n",
       " '_subject': rdflib.term.URIRef('file:///Colonna_Centrale_Colonna_Dorica_Centrale_142138_2m5cC6lu9D_9s0K5cLgC0W'),\n",
       " '_graph': None,\n",
       " '_graphPath': None,\n",
       " '_path': None,\n",
       " '_name': 'Colonna_Centrale:Colonna_Dorica_Centrale:142138',\n",
       " '_timestamp': '2023-02-01T08:36:38',\n",
       " '_resource': TriangleMesh with 2424 points and 4844 triangles.,\n",
       " '_cartesianTransform': array([[  1.        ,   0.        ,   0.        ,   5.38578626],\n",
       "        [  0.        ,   1.        ,   0.        , 257.82303777],\n",
       "        [  0.        ,   0.        ,   1.        ,  -6.00745486],\n",
       "        [  0.        ,   0.        ,   0.        ,   1.        ]]),\n",
       " 'offsetTransform': array([[  1.        ,   0.        ,   0.        ,   5.38578626],\n",
       "        [  0.        ,   1.        ,   0.        , 257.82303777],\n",
       "        [  0.        ,   0.        ,   1.        ,  -6.00745486],\n",
       "        [  0.        ,   0.        ,   0.        ,   1.        ]]),\n",
       " 'className': 'IfcColumn',\n",
       " 'pointCount': 2424,\n",
       " 'faceCount': 4844}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{key:value for key, value in bimNodes[2].__dict__.items() if not key.startswith('__') and not callable(key)}              "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the BIM Classes in different colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: De aangevraagde overdrachtsbewerking wordt niet ondersteund. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: De aangevraagde overdrachtsbewerking wordt niet ondersteund. \n"
     ]
    }
   ],
   "source": [
    "coloredGeometries=[g.paint_uniform_color(ut.random_color()) for g in materialGeometries if g is not None]\n",
    "\n",
    "o3d.visualization.draw_geometries(coloredGeometries)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEGMENT PCD WITH BIM USING LASPY"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Las data (1.5 min for 110M points, requires 13Gb RAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import laspy\n",
    "las  = laspy.read(lasPath)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute nearest neighbors between BIM and point cloud. Fast but operates on single core (10min for 110M points at 0.1m resolution, 13Gb RAM required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_cloud,ref_arr=gmu.create_identity_point_cloud([n.resource for n in bimNodes],resolution=resolution)\n",
    "query_points=gmu.transform_points( las.xyz,bimTransform)\n",
    "indices,distances=gmu.compute_nearest_neighbors(query_points,np.asarray(ref_cloud.points))\n",
    "index=ref_arr[indices]\n",
    "distances=distances[:,0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Optionally): use normals and distanceThreshold to filter it better. (takes twice as long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_cloud,ref_arr=gmu.create_identity_point_cloud([n.resource for n in bimNodes],resolution=resolution,getNormals=True)\n",
    "query_points,query_normals=gmu.get_points_and_normals(las,transform=bimTransform,getNormals=True)\n",
    "reference_points,reference_normals=gmu.get_points_and_normals(ref_cloud,getNormals=True)\n",
    "indices,distances=gmu.compute_nearest_neighbor_with_normal_filtering(query_points,query_normals,reference_points,reference_normals,distanceThreshold=distanceThreshold)\n",
    "index=ref_arr[indices]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fig.**: Nearest neighbor estimation (a) without normal filtering and (b) with normal filtering. Last Figure is the assignment of BIM information in the las point cloud.\n",
    "\n",
    "<img src=\"../docs/pics/colosseum/normal_filtering0.PNG\" width = \"20%\">\n",
    "<img src=\"../docs/pics/colosseum/normal_filtering1.PNG\" width = \"22%\">\n",
    "<img src=\"../docs/pics/colosseum/laspy1.PNG\" width = \"50%\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map index to Building techniques and materials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "BuildingTechniqueArray=np.zeros(len(las.xyz))\n",
    "materialsArray1=np.zeros(len(las.xyz))\n",
    "materialsArray2=np.zeros(len(las.xyz))\n",
    "\n",
    "for ind in np.unique(index):\n",
    "    locations=np.where(index ==ind)\n",
    "    np.put(BuildingTechniqueArray,locations,bimNodes[ind].bimClassField)\n",
    "    np.put(materialsArray1,locations,bimNodes[ind].materialField1)\n",
    "    np.put(materialsArray2,locations,bimNodes[ind].materialField2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign building technique, 1st material, 2nd material and distance to the BIM as extra dimensions in the las file. (query points take 4Gb with 110M points so put it in function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X', 'Y', 'Z', 'intensity', 'return_number', 'number_of_returns', 'scan_direction_flag', 'edge_of_flight_line', 'classification', 'synthetic', 'key_point', 'withheld', 'scan_angle_rank', 'user_data', 'point_source_id', 'red', 'green', 'blue', '01 Materiali', '03 D', '02 TC', 'Original cloud index', 'bimTC', 'bimMaterial1', 'bimMaterial2', 'bimDistance']\n"
     ]
    }
   ],
   "source": [
    "gmu.las_add_extra_dimensions(las,(BuildingTechniqueArray,materialsArray1,materialsArray2,distances),['bimTC','bimMaterial1','bimMaterial2','bimDistance'],['uint8','uint8','uint8','float32'])\n",
    "print(list(las.point_format.dimension_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 0 0 0]\n",
      "[255 255 255 ...   1   1   1]\n",
      "[255 255 255 ... 255 255 255]\n",
      "[0.03154535 0.07160249 0.0433292  ... 0.04762131 0.04273732 0.01054358]\n"
     ]
    }
   ],
   "source": [
    "print(las['bimTC'])\n",
    "print(las['bimMaterial1'])\n",
    "print(las['bimMaterial2'])\n",
    "print(las['bimDistance'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export las file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "las.write(outputlasPath)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fig.**: Images of the segmented point cloud with (a) Point cloud enirched with bim class as a feature (b) the ref_clouds from the BIM model, (c) the initial point cloud.\n",
    "\n",
    "<img src=\"../docs/pics/colosseum/columns5.PNG\" width = \"17%\">\n",
    "<img src=\"../docs/pics/colosseum/columns6.PNG\" width = \"23%\">\n",
    "<img src=\"../docs/pics/colosseum/columns7.PNG\" width = \"23%\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEGMENT PCD AS DATAFRAME"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Without optimization (fast but for small point clouds e.g. 10-20M points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "df = pd.read_csv(csvPath,\n",
    "    sep= ' ',\n",
    "    header=0,  \n",
    "    names=[\"x\",\"y\",\"z\",\"R\", \"G\", \"B\", \"M\", \"TC\", \"Nx\", \"Ny\", \"Nz\" ])\n",
    "arr=np.zeros(len(df))\n",
    "pcd=gmu.dataframe_to_pcd(df)\n",
    "# pcd.transform(bimTransform)\n",
    "#compute distance to identityPointCloud   \n",
    "for i,ref_cloud in enumerate(ref_clouds):\n",
    "    time\n",
    "    distances=pcd.compute_point_cloud_distance(ref_cloud)\n",
    "    #select indices within a distance threshold\n",
    "    indices=np.where(np.asarray(distances) <= threshold)[0]\n",
    "    np.put(arr, indices, i)\n",
    "# assign new column and export df\n",
    "df = df.assign(className=arr)\n",
    "\n",
    "# df['class'] = arr.tolist()\n",
    "df.to_csv(csvPath,mode='a', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i,ref_cloud,name in zip(range(len(bimClasses.values())),ref_clouds,bimClassNames):\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Chunked without optimization (slow but memory proof for medium point clouds e.g. 20-100M points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks  = pd.read_csv(csvPath,\n",
    "    sep= ' ',\n",
    "    header=0,  \n",
    "    names=[\"x\",\"y\",\"z\",\"R\", \"G\", \"B\", \"M\", \"TC\", \"Nx\", \"Ny\", \"Nz\" ],\n",
    "    chunksize=chunksize,\n",
    "    iterator=True)\n",
    "for chunk in chunks: \n",
    "    # create integer based array for the classes\n",
    "    arr=np.zeros(len(chunk))   \n",
    "    #create point cloud\n",
    "    pcd=gmu.dataframe_to_pcd(chunk)\n",
    "    #transform to local coordinate system\n",
    "    pcd.transform(bimTransform)\n",
    "    #compute distance to identityPointCloud    \n",
    "    for i,ref_cloud in enumerate(ref_clouds):\n",
    "        distances=pcd.compute_point_cloud_distance(ref_cloud)\n",
    "        #select indices within a distance threshold       \n",
    "        ind=np.where(np.asarray(distances) <= threshold)[0]\n",
    "        np.put(arr, indices, i)\n",
    "    # assign new column and export df\n",
    "    df['class'] = arr  \n",
    "    chunk.to_csv(csvPath, mode='a', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "#  # this is some unused code to iteratively write data to csv file\n",
    "#   test1=chunk.iloc[ind]\n",
    "#             # #export point clouds\n",
    "#             with open(os.path.join(ClassPointCloudsFolder,name+'.csv'), \"a\") as csv:\n",
    "#                 test1.to_csv(csv,mode='a')\n",
    "#             print(f'{len(test1)} of {chunksize} exported.')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. DASK multiprocessing optimization (fast and memory proof for large point clouds e.g. >100M points). Note that this is three times slower for small point clouds due to working spawning, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 //X             Y          Z    R    G   B  01_Materiali  \\\n",
      "0       2.311879e+06  4.640674e+06  32.195537   74   67  58           0.0   \n",
      "1       2.311879e+06  4.640674e+06  32.184521   90   84  73           0.0   \n",
      "2       2.311879e+06  4.640674e+06  32.204296  117  102  89           0.0   \n",
      "3       2.311879e+06  4.640674e+06  32.212200  116  106  91           0.0   \n",
      "4       2.311879e+06  4.640673e+06  32.135959   79   68  57           0.0   \n",
      "...              ...           ...        ...  ...  ...  ..           ...   \n",
      "571611  2.311875e+06  4.640673e+06  35.283402   46   54  49           0.0   \n",
      "571612  2.311875e+06  4.640673e+06  35.177899   80   80  81           0.0   \n",
      "571613  2.311875e+06  4.640673e+06  35.307801   44   51  48           0.0   \n",
      "571614  2.311875e+06  4.640673e+06  35.254101   96  101  98           0.0   \n",
      "571615  2.311875e+06  4.640673e+06  35.325299   87   88  90           0.0   \n",
      "\n",
      "        03_D  02_TC  Original_cloud_index        Nx        Ny        Nz  \\\n",
      "0        1.0    0.0                   0.0  0.120092  0.920706  0.371319   \n",
      "1        1.0    0.0                   0.0 -0.091646  0.994860 -0.043063   \n",
      "2        1.0    0.0                   0.0  0.882805  0.443570  0.154599   \n",
      "3        1.0    0.0                   0.0  0.601004 -0.043633 -0.798054   \n",
      "4        1.0    0.0                   0.0  0.866770  0.012094 -0.498561   \n",
      "...      ...    ...                   ...       ...       ...       ...   \n",
      "571611   2.0    0.0                   3.0 -0.869342 -0.397370 -0.293841   \n",
      "571612   2.0    0.0                   3.0 -0.910107  0.413445  0.027739   \n",
      "571613   2.0    0.0                   3.0 -0.030668 -0.965433 -0.258839   \n",
      "571614   2.0    0.0                   3.0 -0.532037 -0.806637 -0.257437   \n",
      "571615   2.0    0.0                   3.0 -0.531527  0.014953 -0.846909   \n",
      "\n",
      "        distance_to_ref  \n",
      "0          5.184515e+06  \n",
      "1          5.184516e+06  \n",
      "2          5.184515e+06  \n",
      "3          5.184515e+06  \n",
      "4          5.184515e+06  \n",
      "...                 ...  \n",
      "571611     5.184513e+06  \n",
      "571612     5.184513e+06  \n",
      "571613     5.184513e+06  \n",
      "571614     5.184513e+06  \n",
      "571615     5.184513e+06  \n",
      "\n",
      "[3424050 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "df = dd.read_csv(csvPath,\n",
    "                 header=0, \n",
    "                sep= ' ')\n",
    "\n",
    "\n",
    "def create_and_compute_distance(partition, ref_clouds):\n",
    "    points=partition[partition.columns[:3]].values    \n",
    "    pcd = o3d.geometry.PointCloud(o3d.utility.Vector3dVector(points))\n",
    "    for i,ref_cloud,name in zip(range(len(bimClasses.values())),ref_clouds,bimClassNames):\n",
    "        distances=pcd.compute_point_cloud_distance(ref_cloud)\n",
    "        #select indices within a distance threshold       \n",
    "        ind=np.where(np.asarray(distances) <= threshold)[0]\n",
    "        np.put(arr, indices, i)\n",
    "    distance = pcd.compute_point_cloud_distance(ref_cloud)\n",
    "    \n",
    "    partition['distance_to_ref'] = distance\n",
    "    return partition\n",
    "\n",
    "def create_point_cloud_dask(df, ref_cloud):\n",
    "    point_cloud_partitions = df.map_partitions(create_and_compute_distance, ref_clouds)\n",
    "    return point_cloud_partitions.compute()\n",
    "\n",
    "result = create_point_cloud_dask(df, ref_clouds).to_parquet\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first dask attempt\n",
    "# #define a function\n",
    "# def compute_index(df):\n",
    "#     xyz=df.iloc[:,[0,1,2]]\n",
    "#     pcd=o3d.geometry.PointCloud()\n",
    "#     pcd.points=o3d.utility.Vector3dVector(xyz.to_numpy())\n",
    "#     # pcd=gmu.dataframe_to_pcd(df)\n",
    "#     return 10\n",
    "\n",
    "# #compute function as delayed function\n",
    "# lazy_results = []\n",
    "# for chunk in dask_dataframe: #test\n",
    "#     chunk=chunk.compute()\n",
    "#     lazy_result = dask.delayed(compute_index)(chunk)\n",
    "#     lazy_results.append(lazy_result)\n",
    "# # dask.compute(*lazy_results)\n",
    "# futures = dask.persist(*lazy_results)  # trigger computation in the background\n",
    "# client.cluster.scale(10)  # ask for ten 4-thread workers\n",
    "# results = dask.compute(*futures)\n",
    "# results[:5]\n",
    "\n",
    "\n",
    "# results = dask.compute(*futures)\n",
    "# results[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#this function does not work because you cannot jointly write in parallel in the same file\n",
    "# for chunk in dask_dataframe.partitions:    \n",
    "#     chunk=chunk.compute()\n",
    "#     # print(chunk[0])\n",
    "#     # xyz=chunk.get(['Y', 'Z'])\n",
    "\n",
    "#     pcd=gmu.dataframe_to_pcd(chunk)\n",
    "#     # xyz=chunk.\n",
    "#     # print(pcd)\n",
    "    \n",
    "\n",
    "#     # pcd=o3d.geometry.PointCloud()\n",
    "#     # pcd.points=o3d.utility.Vector3dVector(xyz.to_numpy())\n",
    "#     # #transform to local coordinate system\n",
    "#     pcd.transform(bimTransform)\n",
    "#     #compute distance to identityPointCloud    \n",
    "#     for bimpcd,name in zip(bimPointClouds,bimClassNames):\n",
    "#         distances=pcd.compute_point_cloud_distance(bimpcd)\n",
    "#         #remove distances > threshold\n",
    "#         ind=np.where(np.asarray(distances) <= threshold)[0]\n",
    "#         #select indices based on closest point        \n",
    "#         if ind.size >0:\n",
    "#             test1=chunk.iloc[ind]\n",
    "#             # #export point clouds\n",
    "#             with open(os.path.join(ClassPointCloudsFolder,name+'.csv'), \"a\") as csv:\n",
    "#                 test1.to_csv(csv,mode='a')\n",
    "#             print(f'{len(test1)} of {len(chunk)} exported.')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(optional) filter distance calculation based on geometry shape."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_geomapi2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "42d96290d9f31354e7c0a05dae63dac52e6c4ef16245d374c9299875a30800b0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
