{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BACKPROJECT IMAGE CLASSIFICATION RESULTS ONTO THE POINT CLOUD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph, URIRef\n",
    "import os.path\n",
    "import importlib\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "import open3d as o3d\n",
    "import uuid    \n",
    "import pye57 \n",
    "import ifcopenshell\n",
    "import ifcopenshell.geom as geom\n",
    "import ifcopenshell.util\n",
    "from ifcopenshell.util.selector import Selector\n",
    "import random as rd\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import laspy\n",
    "import copy\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "import pathlib\n",
    "import PIL\n",
    "import PIL.Image\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "import random\n",
    "#IMPORT MODULES\n",
    "from context import geomapi \n",
    "from geomapi.nodes import *\n",
    "import geomapi.utils as ut\n",
    "from geomapi.utils import geometryutils as gmu\n",
    "from geomapi.tools import progresstools as pt\n",
    "from geomapi.utils import imageutils as iu\n",
    "from geomapi.tools import machinelearningtools as mlt\n",
    "\n",
    "import geomapi.tools as tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USER INPUT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "projectPath= os.path.join(\"D:\\\\Data\\\\2023-01 Paestum\")\n",
    "sessionPath = os.path.join(projectPath,\"Research\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCD\n",
    "lasPath=os.path.join(projectPath,\"PCD\",\"dense_point_cloud_0.004.las\")\n",
    "outputlasPath=os.path.join(projectPath,\"PCD\",\"paestum_test1_out.las\")\n",
    "transform=np.array([[1.0,0.0, 0.0,  5.3857862609899980e+000], \n",
    "                [0.0, 1.0, 0.0, 2.5782303777102851e+002],\n",
    "                [0.0, 0.0, 1.0 ,-6.0074548600459288e+000],\n",
    "                [0.0 ,0.0, 0.0, 1.000000000000]]) # -> apply to pcd\n",
    "scale=1/1.8781217664810130e+000 # -> apply to pcd\n",
    "\n",
    "# -10\n",
    "# +10\n",
    "#  5.3857862609899980e+000\n",
    "# 2.5782303777102851e+002 \n",
    "#Images\n",
    "xmlPath=os.path.join(projectPath,'IMG','cameras.xml')\n",
    "sensorid=1\n",
    "focalLength35mm= 2428.49184473261\n",
    "rotation=np.array([[-9.9927572727173009e-001, -9.2989357887395263e-003 ,3.6899196180300041e-002,0],\n",
    "                        [ 3.4752208827689118e-002, 1.7201294833769601e-001, 9.8448150291702796e-001,0],\n",
    "                        [-1.5501769807091738e-002, 9.8505079838421061e-001 , -1.7156520549190035e-001,0],\n",
    "                        [0,0,0,1]]) # -> apply to images\n",
    "       \n",
    "#classification\n",
    "# modelMPath=os.path.join(sessionPath,\"Facade_classification\",\"Model_MobileNetV2__materials\")\n",
    "# modelTCPath=os.path.join(sessionPath,\"Facade_classification\",\"Model_MobileNetV2_BuildingTechniques\")\n",
    "# modelDPath=os.path.join(sessionPath,\"Facade_classification\",\"Model_MobileNetV2_Damages\")\n",
    "# trainingsfolder=pathlib.Path(os.path.join(sessionPath,'shapeConv','temp'))\n",
    "# tf_image_folder=pathlib.Path(os.path.join(sessionPath,'Classification_test1','im_temp'))\n",
    "# tf_mask_folder=pathlib.Path(os.path.join(sessionPath,'Classification_test1','mask_temp'))\n",
    "output_dir=os.path.join(sessionPath,'shapeConv')\n",
    "dir_img=os.path.join(output_dir,'image') # already full\n",
    "dir_class=os.path.join(output_dir,'class') # already full\n",
    "dir_depth=os.path.join(output_dir,'depth') #already full\n",
    "dir_hha=os.path.join(output_dir,'hha') \n",
    "dir_labels=os.path.join(output_dir,'label12')\n",
    "\n",
    "# tempfolder=pathlib.Path(os.path.join(sessionPath,'Facade_classification','temp'))\n",
    "# batch_size = 32 #! same as model\n",
    "# class_names_m=[0.0,1.0]\n",
    "# class_names_tc=[0.0,1.0,2.0]\n",
    "# class_names_d=[1.0,2.0]\n",
    "# imagePath=os.path.join(projectPath,'Research')\n",
    "# filteringWeight=3\n",
    "# colors=[(255,0,0),(0,255,0),(0,0,255)]\n",
    "# pixelRange=224\n",
    "# rayOffsetDistance=0.2\n",
    "skip=300 #nth file tu use\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPROCESS POINT CLOUD"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create point cloud node with proper offset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PointCloud with 2785923 points."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "las  = laspy.read(lasPath)\n",
    "pcdNode=PointCloudNode(name=ut.get_filename(lasPath),\n",
    "                        lasPath=lasPath,\n",
    "                        resource=gmu.las_to_pcd(las,transform=transform)\n",
    "                        )\n",
    "pcdNode.resource.scale(scale,(0,0,0)) #pcdNode.resource.get_center()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPROCESS THE IMAGES WITH THE POINT CLOUD"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create imageNodes with proper offset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "894 Nodes created!\n"
     ]
    }
   ],
   "source": [
    "imgNodes=tl.img_xml_to_nodes(xmlPath,getResource=False)\n",
    "for n in imgNodes:\n",
    "    n.cartesianTransform=rotation @ n.cartesianTransform \n",
    "\n",
    "meshes=[gmu.generate_visual_cone_from_image(n.cartesianTransform, height =0.4) for n in imgNodes]\n",
    "print(str(len(imgNodes))+ \" Nodes created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Nodes created!\n"
     ]
    }
   ],
   "source": [
    "#get list of files\n",
    "files=ut.get_list_of_files(ut.get_folder(xmlPath))\n",
    "files=[f for f in files if f.endswith('.JPG')]\n",
    "\n",
    "#select every fifth files\n",
    "imgNodes=[]\n",
    "for f in files[0::skip]:    \n",
    "    imgNodes.append(ImageNode(name=ut.get_filename(f),\n",
    "              path=f,\n",
    "              xmlPath=xmlPath,\n",
    "                focalLength35mm=focalLength35mm))\n",
    "# apply transform to put imagery in local coordinates\n",
    "for n in imgNodes:\n",
    "    n.cartesianTransform=rotation @ n.cartesianTransform \n",
    "       \n",
    "meshes=[gmu.generate_visual_cone_from_image(n.cartesianTransform, height =0.4) for n in imgNodes]\n",
    "print(str(len(imgNodes))+ \" Nodes created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_xmlPath': 'D:\\\\Data\\\\2023-01 Paestum\\\\IMG\\\\cameras.xml',\n",
       " '_xmpPath': None,\n",
       " '_orientedBoundingBox': None,\n",
       " 'imageWidth': 6048,\n",
       " 'imageHeight': 4032,\n",
       " 'focalLength35mm': 2428.49184473261,\n",
       " 'keypoints': None,\n",
       " 'descriptors': None,\n",
       " '_subject': rdflib.term.URIRef('file:///DSC_4226'),\n",
       " '_graph': None,\n",
       " '_graphPath': None,\n",
       " '_path': 'D:/Data/2023-01 Paestum/IMG/DSC_4226.JPG',\n",
       " '_name': 'DSC_4226',\n",
       " '_timestamp': '2014-06-06T17:21:42',\n",
       " '_resource': None,\n",
       " '_cartesianTransform': array([[  0.01816121,   0.99750693,  -0.06819158,   8.0859977 ],\n",
       "        [ -0.42725536,   0.06940471,   0.90146317, -11.42426073],\n",
       "        [  0.90394857,   0.01276355,   0.42745066,  -2.17309796],\n",
       "        [  0.        ,   0.        ,   0.        ,   1.        ]]),\n",
       " 'resolutionUnit': 2,\n",
       " 'geospatialTransform': [None, None, None],\n",
       " 'coordinateSystem': 'geospatial-wgs84'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{key:value for key, value in imgNodes[0].__dict__.items() if not key.startswith('__') and not callable(key)}              "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualize the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "joinedImages=gmu.join_geometries(meshes)\n",
    "joinedImages=joinedImages.paint_uniform_color([1,0,0])\n",
    "o3d.visualization.draw_geometries([joinedImages]+[pcdNode.resource])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "colorize pcd per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=las['Scalar field #15']\n",
    "values=np.unique(labels)\n",
    "pcd=copy.deepcopy(pcdNode.resource)\n",
    "colors=np.array([ut.random_color() for v in range(len(values))])\n",
    "colorArray=gmu.array_to_colors(labels,colors)\n",
    "pcd.colors=o3d.utility.Vector3dVector(colorArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional\n",
    "octree=pt.pcd_to_octree(pcd,8) #if octree is None else octree\n",
    "mesh=gmu.octree_to_voxelmesh(octree) #if mesh is None else mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([joinedImages]+[mesh])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(optional) Get depth and class labels image per image from the point cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colorImages1,depthImages1=pt.project_pcd_to_rgbd_images(pcd,myImageNodes,depth_max=30,fill_black=40)#\n",
    "# for c,d,n in zip(colorImages1,depthImages1,imgNodes): \n",
    "#     n.mask1=pt.remap_color_images_to_masks(c,colors)[0]\n",
    "#     n.colorImage1=c \n",
    "#     n.depthImage1=d "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get depth and class labels image per image from the octree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Scan-to-BIM repository\\geomapi\\geomapi\\tools\\machinelearningtools\\__init__.py:157: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X_Z = np.divide(X, Z)\n",
      "d:\\Scan-to-BIM repository\\geomapi\\geomapi\\tools\\machinelearningtools\\__init__.py:158: RuntimeWarning: invalid value encountered in true_divide\n",
      "  Y_Z = np.divide(Y, Z)\n",
      "d:\\Scan-to-BIM repository\\geomapi\\geomapi\\tools\\machinelearningtools\\__init__.py:162: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X_ZZ = np.expand_dims(np.divide(X, ZZ), axis=2)\n",
      "d:\\Scan-to-BIM repository\\geomapi\\geomapi\\tools\\machinelearningtools\\__init__.py:163: RuntimeWarning: invalid value encountered in true_divide\n",
      "  Y_ZZ = np.expand_dims(np.divide(Y, ZZ), axis=2)\n",
      "d:\\Scan-to-BIM repository\\geomapi\\geomapi\\tools\\machinelearningtools\\__init__.py:184: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  b = np.divide(-detAtA, divide_fac)\n",
      "d:\\Scan-to-BIM repository\\geomapi\\geomapi\\tools\\machinelearningtools\\__init__.py:184: RuntimeWarning: invalid value encountered in true_divide\n",
      "  b = np.divide(-detAtA, divide_fac)\n",
      "d:\\Scan-to-BIM repository\\geomapi\\geomapi\\tools\\machinelearningtools\\__init__.py:186: RuntimeWarning: invalid value encountered in true_divide\n",
      "  N[:, :, i] = np.divide(N[:, :, i], divide_fac)\n",
      "d:\\Scan-to-BIM repository\\geomapi\\geomapi\\tools\\machinelearningtools\\__init__.py:196: RuntimeWarning: invalid value encountered in multiply\n",
      "  sn = np.sign(np.sum(np.multiply(N, XYZf), axis=2))\n",
      "c:\\Users\\u0094523\\.conda\\envs\\tf_geomapi2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "d:\\Scan-to-BIM repository\\geomapi\\geomapi\\tools\\machinelearningtools\\__init__.py:350: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  s_hat = np.array([[0, -ax[2], ax[1]],\n",
      "c:\\Users\\u0094523\\.conda\\envs\\tf_geomapi2\\lib\\site-packages\\numpy\\lib\\function_base.py:4486: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n"
     ]
    }
   ],
   "source": [
    "octree=pt.pcd_to_octree(pcd,8) #if octree is None else octree\n",
    "mesh=gmu.octree_to_voxelmesh(octree) #if mesh is None else mesh\n",
    "# colorImages2,depthImages2=pt.project_meshes_to_rgbd_images(mesh, imgNodes) # no depth filtering currently\n",
    "width=640\n",
    "height=480\n",
    "extrinsics=[n.cartesianTransform for n in imgNodes]\n",
    "intrinsics=[np.array([[focalLength35mm/(n.imageWidth/width),0,width/2-0.5],[0,focalLength35mm/(n.imageHeight/height),height/2-0.5],[0,0,1]]) for n in imgNodes]\n",
    "colorImages2,depthImages2=gmu.project_meshes_to_rgbd_images(mesh, extrinsics,intrinsics) # no depth filtering currently\n",
    "for c,d,n in zip(colorImages2,depthImages2,imgNodes): \n",
    "    n.resource=iu.image_resize(n.resource,width=width,height=height)\n",
    "    n.mask2=pt.remap_color_images_to_masks(c,colors)[0]\n",
    "    n.colorImage2=c \n",
    "    n.depthImage2=d \n",
    "    n.hha=mlt.depth_map_to_hha(intrinsics[0],d,d) #! this takes 9min per image , perhaps scale it down and up\n",
    "    \n",
    "    # n.hha=mlt.depth_map_to_hha(n.get_intrinsic_camera_parameters().intrinsic_matrix,n.depthImage2,n.depthImage2) #! this takes 9min per image , perhaps scale it down and up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Scan-to-BIM repository\\geomapi\\geomapi\\tools\\machinelearningtools\\__init__.py:157: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X_Z = np.divide(X, Z)\n",
      "d:\\Scan-to-BIM repository\\geomapi\\geomapi\\tools\\machinelearningtools\\__init__.py:158: RuntimeWarning: invalid value encountered in true_divide\n",
      "  Y_Z = np.divide(Y, Z)\n",
      "d:\\Scan-to-BIM repository\\geomapi\\geomapi\\tools\\machinelearningtools\\__init__.py:162: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X_ZZ = np.expand_dims(np.divide(X, ZZ), axis=2)\n",
      "d:\\Scan-to-BIM repository\\geomapi\\geomapi\\tools\\machinelearningtools\\__init__.py:163: RuntimeWarning: invalid value encountered in true_divide\n",
      "  Y_ZZ = np.expand_dims(np.divide(Y, ZZ), axis=2)\n",
      "d:\\Scan-to-BIM repository\\geomapi\\geomapi\\tools\\machinelearningtools\\__init__.py:184: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  b = np.divide(-detAtA, divide_fac)\n",
      "d:\\Scan-to-BIM repository\\geomapi\\geomapi\\tools\\machinelearningtools\\__init__.py:184: RuntimeWarning: invalid value encountered in true_divide\n",
      "  b = np.divide(-detAtA, divide_fac)\n",
      "d:\\Scan-to-BIM repository\\geomapi\\geomapi\\tools\\machinelearningtools\\__init__.py:186: RuntimeWarning: invalid value encountered in true_divide\n",
      "  N[:, :, i] = np.divide(N[:, :, i], divide_fac)\n",
      "d:\\Scan-to-BIM repository\\geomapi\\geomapi\\tools\\machinelearningtools\\__init__.py:196: RuntimeWarning: invalid value encountered in multiply\n",
      "  sn = np.sign(np.sum(np.multiply(N, XYZf), axis=2))\n",
      "c:\\Users\\u0094523\\.conda\\envs\\tf_geomapi2\\lib\\site-packages\\numpy\\core\\fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "d:\\Scan-to-BIM repository\\geomapi\\geomapi\\tools\\machinelearningtools\\__init__.py:350: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  s_hat = np.array([[0, -ax[2], ax[1]],\n",
      "c:\\Users\\u0094523\\.conda\\envs\\tf_geomapi2\\lib\\site-packages\\numpy\\lib\\function_base.py:4486: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n"
     ]
    }
   ],
   "source": [
    "# subdivide images to 640,480\n",
    "octree=pt.pcd_to_octree(pcd,8) #if octree is None else octree\n",
    "mesh=gmu.octree_to_voxelmesh(octree) #if mesh is None else mesh\n",
    "colorImages2,depthImages2=pt.project_meshes_to_rgbd_images(mesh, imgNodes) # no depth filtering currently\n",
    "width=640\n",
    "height=480\n",
    "imgTrainingNodes=[]\n",
    "for c,d,n in zip(colorImages2,depthImages2,imgNodes): \n",
    "    imgList,roiList=iu.subdivide_image(n.resource,m=3,n=3,includeLast=True) \n",
    "    imgList=[iu.image_resize(img, width=640,height=480) for img in imgList ]\n",
    "#     n.resource=iu.image_resize(n.resource,width=width,height=height)\n",
    "    masks,_=iu.subdivide_image(pt.remap_color_images_to_masks(c,colors)[0],m=3,n=3,includeLast=True) \n",
    "    masks=[iu.image_resize(img, width=640,height=480) for img in masks ]\n",
    "    vizs,_=iu.subdivide_image(c ,m=3,n=3,includeLast=True) \n",
    "    vizs=[iu.image_resize(img, width=640,height=480) for img in vizs ]\n",
    "    \n",
    "    depths,_=iu.subdivide_image(d ,m=3,n=3,includeLast=True) \n",
    "    depths=[iu.image_resize(img, width=640,height=480) for img in depths ]\n",
    "    \n",
    "    hhas,_=iu.subdivide_image(mlt.depth_map_to_hha(n.get_intrinsic_camera_parameters().intrinsic_matrix,d,d),m=3,n=3,includeLast=True)  #! this takes 9min per image , perhaps scale it down and up\n",
    "    hhas=[iu.image_resize(img, width=640,height=480) for img in hhas ]\n",
    "    \n",
    "    for img,roi,mask,viz,depth,hha in zip(imgList,roiList,masks,vizs,depths,hhas):\n",
    "        imgTrainingNodes.append(ImageNode(resource=img,\n",
    "                                isDerivedFrom=n.subject,\n",
    "                                roi=roi,\n",
    "                                mask=mask,\n",
    "                                color=viz,\n",
    "                                depth=depth,\n",
    "                                hha=hha))  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize some results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\Scan-to-BIM repository\\geomapi\\examples\\Example_paestum_2_shape_conv.ipynb Cell 29\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Scan-to-BIM%20repository/geomapi/examples/Example_paestum_2_shape_conv.ipynb#X35sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mimport\u001b[39;00m pyplot \u001b[39mas\u001b[39;00m plt\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Scan-to-BIM%20repository/geomapi/examples/Example_paestum_2_shape_conv.ipynb#X35sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmath\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Scan-to-BIM%20repository/geomapi/examples/Example_paestum_2_shape_conv.ipynb#X35sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m n\u001b[39m=\u001b[39mimgNodes[\u001b[39m4\u001b[39;49m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Scan-to-BIM%20repository/geomapi/examples/Example_paestum_2_shape_conv.ipynb#X35sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m fig, axs \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots(\u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m,figsize\u001b[39m=\u001b[39m(\u001b[39m30\u001b[39m, \u001b[39m30\u001b[39m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Scan-to-BIM%20repository/geomapi/examples/Example_paestum_2_shape_conv.ipynb#X35sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m fig\u001b[39m.\u001b[39mset_facecolor(\u001b[39m\"\u001b[39m\u001b[39mwhite\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "n=imgNodes[random.randint(  0,len(imgNodes))]\n",
    "fig, axs = plt.subplots(1, 3,figsize=(30, 30))\n",
    "fig.set_facecolor(\"white\")\n",
    "axs[0].imshow(iu.image_resize(n.resource,scale=1/1))\n",
    "axs[1].imshow(iu.image_resize(n.colorImage2,scale=1/1))\n",
    "axs[2].imshow(iu.image_resize(n.hha,scale=1/1))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(optional) write class labels to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.rmtree(dir_img) if os.path.exists(dir_img) else None \n",
    "os.mkdir(dir_img) if not os.path.exists(dir_img) else None \n",
    "shutil.rmtree(dir_class) if os.path.exists(dir_class) else None \n",
    "os.mkdir(dir_class) if not os.path.exists(dir_class) else None                      \n",
    "shutil.rmtree(dir_depth) if os.path.exists(dir_depth) else None \n",
    "os.mkdir(dir_depth) if not os.path.exists(dir_depth) else None    \n",
    "shutil.rmtree(dir_hha) if os.path.exists(dir_hha) else None \n",
    "os.mkdir(dir_hha) if not os.path.exists(dir_hha) else None    \n",
    "shutil.rmtree(dir_labels) if os.path.exists(dir_labels) else None \n",
    "os.mkdir(dir_labels) if not os.path.exists(dir_labels) else None  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in imgTrainingNodes:\n",
    "    n.color=np.round(n.color*255,0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = []\n",
    "test_list = []\n",
    "\n",
    "for i,n in enumerate(imgTrainingNodes):\n",
    "    #save image\n",
    "    cv2.imwrite(os.path.join(dir_img,n.name+'.png'), n.resource)\n",
    "    #class image\n",
    "    # classImg=iu.grb01_to_rgb255(n.colorImage2)\n",
    "    cv2.imwrite(os.path.join(dir_class,n.name+'.png'), n.color)\n",
    "    #depth\n",
    "    cv2.imwrite(os.path.join(dir_depth,n.name+'.png'), n.depth)\n",
    "    #hha\n",
    "    cv2.imwrite(os.path.join(dir_hha,n.name+'.png'), n.hha)  \n",
    "    #labels\n",
    "    cv2.imwrite(os.path.join(dir_labels,n.name+'.png'), n.mask)\n",
    "\n",
    "    if i%2 ==0:\n",
    "        train_list.append(n.name)\n",
    "    else:\n",
    "        test_list.append(n.name)\n",
    "\n",
    "def write_txt(path_list, names):\n",
    "    with open(path_list, 'w') as f:\n",
    "        [f.write(name+'\\n') for name in names]\n",
    "\n",
    "path_list = os.path.join(output_dir, 'train.txt')\n",
    "write_txt(path_list, train_list)\n",
    "\n",
    "path_list = os.path.join(output_dir, 'test.txt')\n",
    "write_txt(path_list, test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n",
      "38\n"
     ]
    }
   ],
   "source": [
    "path='D:/Data/2023-01 NYU_v2/nyu_v2/depth'\n",
    "import glob\n",
    "test1 = cv2.imread('D:/Data/2023-01 Paestum/Research/shapeConv/depth/IMG_0609.png',cv2.IMREAD_GRAYSCALE)\n",
    "print(test1.max())\n",
    "\n",
    "test2 = cv2.imread('D:/Data/2023-01 NYU_v2/nyu_v2/depth/000117.png',cv2.IMREAD_GRAYSCALE)\n",
    "print(test2.max())\n",
    "# depth is different. we have inf and they have 14\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_geomapi2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "42d96290d9f31354e7c0a05dae63dac52e6c4ef16245d374c9299875a30800b0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
